{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "- This project aims to collect and find data sources to use for analytics tables, app back-end, and source-of-truth databases.\n",
    "- The data will be checked for quality issues and necessary cleaning steps will be noted. The next steps will involve creating a data model and pipelines, while ensuring that the data quality checks and integrity constraints are in place.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import isnan, when, count, col, substring, udf, sum\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()\n",
    "    return spark\n",
    "spark=create_spark_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "In this project, I aim to analyze and model four different datasets to prepare them for end use cases such as analytics tables, app back-end, and source-of-truth databases. I will identify and gather data from at least two sources, which include immigration data to the United States, airport codes, demographic data of U.S. cities, and temperature data. I will explore and assess the data to identify any data quality issues, document necessary cleaning steps, and define a data model. The data model will be pipelined with the data and ETL will be run to create the data pipelines and the data model. Additionally, I will ensure data quality checks, integrity constraints, and perform unit tests for the scripts to ensure that they are functioning correctly.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "The four datasets used in this project are:\n",
    "\n",
    "***Immigration data to the United States (df_Immigration_sample)***\n",
    "\n",
    "***Temperature data (df_temp)***\n",
    "\n",
    "***Demographic data of U.S. cities (df_demographics)***\n",
    "\n",
    "***Airport codes (df_airport_codes)***\n",
    "\n",
    "The immigration data is a sample dataset that includes information on immigrants to the United States, including their country of origin, mode of transportation, and arrival date. The temperature data contains information on the temperatures of various cities around the world. The demographic data of U.S. cities includes information on the racial and ethnic makeup of cities in the United States. The airport codes dataset includes information on airport codes and their corresponding cities and countries. All datasets were obtained from publicly available sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data here :\n",
    "df_Immigration_sample = pd.read_csv('./immigration_data_sample.csv')\n",
    "df_temp = pd.read_csv('../../data2/GlobalLandTemperaturesByCity.csv')\n",
    "df_demographics = pd.read_csv(\"./us-cities-demographics.csv\", delimiter=\";\")\n",
    "df_airport_codes = pd.read_csv(\"./airport-codes_csv.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing the head of the first dataset df_i94:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "\n",
       "   i94mode i94addr    ...     entdepu  matflag  biryear   dtaddto  gender  \\\n",
       "0      1.0      HI    ...         NaN        M   1955.0  07202016       F   \n",
       "1      1.0      TX    ...         NaN        M   1990.0  10222016       M   \n",
       "2      1.0      FL    ...         NaN        M   1940.0  07052016       M   \n",
       "3      1.0      CA    ...         NaN        M   1991.0  10272016       M   \n",
       "4      3.0      NY    ...         NaN        M   1997.0  07042016       F   \n",
       "\n",
       "  insnum airline        admnum  fltno  visatype  \n",
       "0    NaN      JL  5.658267e+10  00782        WT  \n",
       "1    NaN     *GA  9.436200e+10  XBLNG        B2  \n",
       "2    NaN      LH  5.578047e+10  00464        WT  \n",
       "3    NaN      QR  9.478970e+10  00739        B2  \n",
       "4    NaN     NaN  4.232257e+10   LAND        WT  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Immigration_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 29 columns):\n",
      "Unnamed: 0    1000 non-null int64\n",
      "cicid         1000 non-null float64\n",
      "i94yr         1000 non-null float64\n",
      "i94mon        1000 non-null float64\n",
      "i94cit        1000 non-null float64\n",
      "i94res        1000 non-null float64\n",
      "i94port       1000 non-null object\n",
      "arrdate       1000 non-null float64\n",
      "i94mode       1000 non-null float64\n",
      "i94addr       941 non-null object\n",
      "depdate       951 non-null float64\n",
      "i94bir        1000 non-null float64\n",
      "i94visa       1000 non-null float64\n",
      "count         1000 non-null float64\n",
      "dtadfile      1000 non-null int64\n",
      "visapost      382 non-null object\n",
      "occup         4 non-null object\n",
      "entdepa       1000 non-null object\n",
      "entdepd       954 non-null object\n",
      "entdepu       0 non-null float64\n",
      "matflag       954 non-null object\n",
      "biryear       1000 non-null float64\n",
      "dtaddto       1000 non-null object\n",
      "gender        859 non-null object\n",
      "insnum        35 non-null float64\n",
      "airline       967 non-null object\n",
      "admnum        1000 non-null float64\n",
      "fltno         992 non-null object\n",
      "visatype      1000 non-null object\n",
      "dtypes: float64(15), int64(2), object(12)\n",
      "memory usage: 226.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_Immigration_sample.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describing the first dataset df_i94:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>biryear</th>\n",
       "      <th>insnum</th>\n",
       "      <th>admnum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>951.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.542097e+06</td>\n",
       "      <td>3.040461e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>302.928000</td>\n",
       "      <td>298.26200</td>\n",
       "      <td>20559.680000</td>\n",
       "      <td>1.078000</td>\n",
       "      <td>20575.037855</td>\n",
       "      <td>42.382000</td>\n",
       "      <td>1.859000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.016042e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1973.618000</td>\n",
       "      <td>3826.857143</td>\n",
       "      <td>6.937237e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.152879e+05</td>\n",
       "      <td>1.799818e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>206.485285</td>\n",
       "      <td>202.12039</td>\n",
       "      <td>8.995027</td>\n",
       "      <td>0.485955</td>\n",
       "      <td>24.211234</td>\n",
       "      <td>17.903424</td>\n",
       "      <td>0.386353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.951657e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.903424</td>\n",
       "      <td>221.742583</td>\n",
       "      <td>2.338134e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.092500e+04</td>\n",
       "      <td>1.320800e+04</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>103.00000</td>\n",
       "      <td>20545.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20547.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.016040e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1923.000000</td>\n",
       "      <td>3468.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.214422e+05</td>\n",
       "      <td>1.412170e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>131.00000</td>\n",
       "      <td>20552.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20561.000000</td>\n",
       "      <td>30.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.016041e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1961.000000</td>\n",
       "      <td>3668.000000</td>\n",
       "      <td>5.599301e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.494568e+06</td>\n",
       "      <td>2.941176e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>213.00000</td>\n",
       "      <td>20560.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20570.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.016042e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1974.000000</td>\n",
       "      <td>3887.000000</td>\n",
       "      <td>5.931477e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.360901e+06</td>\n",
       "      <td>4.694151e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>438.000000</td>\n",
       "      <td>438.00000</td>\n",
       "      <td>20567.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20580.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.016042e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1985.250000</td>\n",
       "      <td>3943.000000</td>\n",
       "      <td>9.343623e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.095749e+06</td>\n",
       "      <td>6.061994e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>696.00000</td>\n",
       "      <td>20574.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>20715.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.016080e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>4686.000000</td>\n",
       "      <td>9.502151e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0         cicid   i94yr  i94mon       i94cit      i94res  \\\n",
       "count  1.000000e+03  1.000000e+03  1000.0  1000.0  1000.000000  1000.00000   \n",
       "mean   1.542097e+06  3.040461e+06  2016.0     4.0   302.928000   298.26200   \n",
       "std    9.152879e+05  1.799818e+06     0.0     0.0   206.485285   202.12039   \n",
       "min    1.092500e+04  1.320800e+04  2016.0     4.0   103.000000   103.00000   \n",
       "25%    7.214422e+05  1.412170e+06  2016.0     4.0   135.000000   131.00000   \n",
       "50%    1.494568e+06  2.941176e+06  2016.0     4.0   213.000000   213.00000   \n",
       "75%    2.360901e+06  4.694151e+06  2016.0     4.0   438.000000   438.00000   \n",
       "max    3.095749e+06  6.061994e+06  2016.0     4.0   746.000000   696.00000   \n",
       "\n",
       "            arrdate      i94mode       depdate       i94bir      i94visa  \\\n",
       "count   1000.000000  1000.000000    951.000000  1000.000000  1000.000000   \n",
       "mean   20559.680000     1.078000  20575.037855    42.382000     1.859000   \n",
       "std        8.995027     0.485955     24.211234    17.903424     0.386353   \n",
       "min    20545.000000     1.000000  20547.000000     1.000000     1.000000   \n",
       "25%    20552.000000     1.000000  20561.000000    30.750000     2.000000   \n",
       "50%    20560.000000     1.000000  20570.000000    42.000000     2.000000   \n",
       "75%    20567.250000     1.000000  20580.000000    55.000000     2.000000   \n",
       "max    20574.000000     9.000000  20715.000000    93.000000     3.000000   \n",
       "\n",
       "        count      dtadfile  entdepu      biryear       insnum        admnum  \n",
       "count  1000.0  1.000000e+03      0.0  1000.000000    35.000000  1.000000e+03  \n",
       "mean      1.0  2.016042e+07      NaN  1973.618000  3826.857143  6.937237e+10  \n",
       "std       0.0  4.951657e+01      NaN    17.903424   221.742583  2.338134e+10  \n",
       "min       1.0  2.016040e+07      NaN  1923.000000  3468.000000  0.000000e+00  \n",
       "25%       1.0  2.016041e+07      NaN  1961.000000  3668.000000  5.599301e+10  \n",
       "50%       1.0  2.016042e+07      NaN  1974.000000  3887.000000  5.931477e+10  \n",
       "75%       1.0  2.016042e+07      NaN  1985.250000  3943.000000  9.343623e+10  \n",
       "max       1.0  2.016080e+07      NaN  2015.000000  4686.000000  9.502151e+10  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Immigration_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_immigration = pd.read_sas('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat', 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN     NaN   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U      NaN   1979.0  10282016    NaN    NaN   \n",
       "1      NaN   ...           Y      NaN   1991.0       D/S      M    NaN   \n",
       "2  20691.0   ...         NaN        M   1961.0  09302016      M    NaN   \n",
       "3  20567.0   ...         NaN        M   1988.0  09302016    NaN    NaN   \n",
       "4  20567.0   ...         NaN        M   2012.0  09302016    NaN    NaN   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0     NaN  1.897628e+09    NaN       B2  \n",
       "1     NaN  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df_immigration.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3096313 entries, 0 to 3096312\n",
      "Data columns (total 28 columns):\n",
      "cicid       float64\n",
      "i94yr       float64\n",
      "i94mon      float64\n",
      "i94cit      float64\n",
      "i94res      float64\n",
      "i94port     object\n",
      "arrdate     float64\n",
      "i94mode     float64\n",
      "i94addr     object\n",
      "depdate     float64\n",
      "i94bir      float64\n",
      "i94visa     float64\n",
      "count       float64\n",
      "dtadfile    object\n",
      "visapost    object\n",
      "occup       object\n",
      "entdepa     object\n",
      "entdepd     object\n",
      "entdepu     object\n",
      "matflag     object\n",
      "biryear     float64\n",
      "dtaddto     object\n",
      "gender      object\n",
      "insnum      object\n",
      "airline     object\n",
      "admnum      float64\n",
      "fltno       object\n",
      "visatype    object\n",
      "dtypes: float64(13), object(15)\n",
      "memory usage: 661.4+ MB\n"
     ]
    }
   ],
   "source": [
    "full_df_immigration.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>biryear</th>\n",
       "      <th>admnum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.096313e+06</td>\n",
       "      <td>3096313.0</td>\n",
       "      <td>3096313.0</td>\n",
       "      <td>3.096313e+06</td>\n",
       "      <td>3.096313e+06</td>\n",
       "      <td>3.096313e+06</td>\n",
       "      <td>3.096074e+06</td>\n",
       "      <td>2.953856e+06</td>\n",
       "      <td>3.095511e+06</td>\n",
       "      <td>3.096313e+06</td>\n",
       "      <td>3096313.0</td>\n",
       "      <td>3.095511e+06</td>\n",
       "      <td>3.096313e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.078652e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.049069e+02</td>\n",
       "      <td>3.032838e+02</td>\n",
       "      <td>2.055985e+04</td>\n",
       "      <td>1.073690e+00</td>\n",
       "      <td>2.057395e+04</td>\n",
       "      <td>4.176761e+01</td>\n",
       "      <td>1.845393e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.974232e+03</td>\n",
       "      <td>7.082885e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.763278e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.100269e+02</td>\n",
       "      <td>2.085832e+02</td>\n",
       "      <td>8.777339e+00</td>\n",
       "      <td>5.158963e-01</td>\n",
       "      <td>2.935697e+01</td>\n",
       "      <td>1.742026e+01</td>\n",
       "      <td>3.983910e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.742026e+01</td>\n",
       "      <td>2.215442e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.010000e+02</td>\n",
       "      <td>1.010000e+02</td>\n",
       "      <td>2.054500e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.517600e+04</td>\n",
       "      <td>-3.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.902000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.577790e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.350000e+02</td>\n",
       "      <td>1.310000e+02</td>\n",
       "      <td>2.055200e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.056100e+04</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.962000e+03</td>\n",
       "      <td>5.603523e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.103507e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.130000e+02</td>\n",
       "      <td>2.130000e+02</td>\n",
       "      <td>2.056000e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.057000e+04</td>\n",
       "      <td>4.100000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.975000e+03</td>\n",
       "      <td>5.936094e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.654341e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.120000e+02</td>\n",
       "      <td>5.040000e+02</td>\n",
       "      <td>2.056700e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.057900e+04</td>\n",
       "      <td>5.400000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.986000e+03</td>\n",
       "      <td>9.350987e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.102785e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.990000e+02</td>\n",
       "      <td>7.600000e+02</td>\n",
       "      <td>2.057400e+04</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>4.542700e+04</td>\n",
       "      <td>1.140000e+02</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.019000e+03</td>\n",
       "      <td>9.991557e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              cicid      i94yr     i94mon        i94cit        i94res  \\\n",
       "count  3.096313e+06  3096313.0  3096313.0  3.096313e+06  3.096313e+06   \n",
       "mean   3.078652e+06     2016.0        4.0  3.049069e+02  3.032838e+02   \n",
       "std    1.763278e+06        0.0        0.0  2.100269e+02  2.085832e+02   \n",
       "min    6.000000e+00     2016.0        4.0  1.010000e+02  1.010000e+02   \n",
       "25%    1.577790e+06     2016.0        4.0  1.350000e+02  1.310000e+02   \n",
       "50%    3.103507e+06     2016.0        4.0  2.130000e+02  2.130000e+02   \n",
       "75%    4.654341e+06     2016.0        4.0  5.120000e+02  5.040000e+02   \n",
       "max    6.102785e+06     2016.0        4.0  9.990000e+02  7.600000e+02   \n",
       "\n",
       "            arrdate       i94mode       depdate        i94bir       i94visa  \\\n",
       "count  3.096313e+06  3.096074e+06  2.953856e+06  3.095511e+06  3.096313e+06   \n",
       "mean   2.055985e+04  1.073690e+00  2.057395e+04  4.176761e+01  1.845393e+00   \n",
       "std    8.777339e+00  5.158963e-01  2.935697e+01  1.742026e+01  3.983910e-01   \n",
       "min    2.054500e+04  1.000000e+00  1.517600e+04 -3.000000e+00  1.000000e+00   \n",
       "25%    2.055200e+04  1.000000e+00  2.056100e+04  3.000000e+01  2.000000e+00   \n",
       "50%    2.056000e+04  1.000000e+00  2.057000e+04  4.100000e+01  2.000000e+00   \n",
       "75%    2.056700e+04  1.000000e+00  2.057900e+04  5.400000e+01  2.000000e+00   \n",
       "max    2.057400e+04  9.000000e+00  4.542700e+04  1.140000e+02  3.000000e+00   \n",
       "\n",
       "           count       biryear        admnum  \n",
       "count  3096313.0  3.095511e+06  3.096313e+06  \n",
       "mean         1.0  1.974232e+03  7.082885e+10  \n",
       "std          0.0  1.742026e+01  2.215442e+10  \n",
       "min          1.0  1.902000e+03  0.000000e+00  \n",
       "25%          1.0  1.962000e+03  5.603523e+10  \n",
       "50%          1.0  1.975000e+03  5.936094e+10  \n",
       "75%          1.0  1.986000e+03  9.350987e+10  \n",
       "max          1.0  2.019000e+03  9.991557e+10  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df_immigration.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_immigration.to_csv('./Cleaned Data/full_immigration.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing the head of the second dataset df_temp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8599212 entries, 0 to 8599211\n",
      "Data columns (total 7 columns):\n",
      "dt                               object\n",
      "AverageTemperature               float64\n",
      "AverageTemperatureUncertainty    float64\n",
      "City                             object\n",
      "Country                          object\n",
      "Latitude                         object\n",
      "Longitude                        object\n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 459.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_temp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Describing the second dataset df_temp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.235082e+06</td>\n",
       "      <td>8.235082e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.672743e+01</td>\n",
       "      <td>1.028575e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.035344e+01</td>\n",
       "      <td>1.129733e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.270400e+01</td>\n",
       "      <td>3.400000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.029900e+01</td>\n",
       "      <td>3.370000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.883100e+01</td>\n",
       "      <td>5.910000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.521000e+01</td>\n",
       "      <td>1.349000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.965100e+01</td>\n",
       "      <td>1.539600e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AverageTemperature  AverageTemperatureUncertainty\n",
       "count        8.235082e+06                   8.235082e+06\n",
       "mean         1.672743e+01                   1.028575e+00\n",
       "std          1.035344e+01                   1.129733e+00\n",
       "min         -4.270400e+01                   3.400000e-02\n",
       "25%          1.029900e+01                   3.370000e-01\n",
       "50%          1.883100e+01                   5.910000e-01\n",
       "75%          2.521000e+01                   1.349000e+00\n",
       "max          3.965100e+01                   1.539600e+01"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing the head of the third dataset df_demographics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2891 entries, 0 to 2890\n",
      "Data columns (total 12 columns):\n",
      "City                      2891 non-null object\n",
      "State                     2891 non-null object\n",
      "Median Age                2891 non-null float64\n",
      "Male Population           2888 non-null float64\n",
      "Female Population         2888 non-null float64\n",
      "Total Population          2891 non-null int64\n",
      "Number of Veterans        2878 non-null float64\n",
      "Foreign-born              2878 non-null float64\n",
      "Average Household Size    2875 non-null float64\n",
      "State Code                2891 non-null object\n",
      "Race                      2891 non-null object\n",
      "Count                     2891 non-null int64\n",
      "dtypes: float64(6), int64(2), object(4)\n",
      "memory usage: 271.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_demographics.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describing the third dataset df_demographics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2891.000000</td>\n",
       "      <td>2.888000e+03</td>\n",
       "      <td>2.888000e+03</td>\n",
       "      <td>2.891000e+03</td>\n",
       "      <td>2878.000000</td>\n",
       "      <td>2.878000e+03</td>\n",
       "      <td>2875.000000</td>\n",
       "      <td>2.891000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>35.494881</td>\n",
       "      <td>9.732843e+04</td>\n",
       "      <td>1.017696e+05</td>\n",
       "      <td>1.989668e+05</td>\n",
       "      <td>9367.832523</td>\n",
       "      <td>4.065360e+04</td>\n",
       "      <td>2.742543</td>\n",
       "      <td>4.896377e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.401617</td>\n",
       "      <td>2.162999e+05</td>\n",
       "      <td>2.315646e+05</td>\n",
       "      <td>4.475559e+05</td>\n",
       "      <td>13211.219924</td>\n",
       "      <td>1.557491e+05</td>\n",
       "      <td>0.433291</td>\n",
       "      <td>1.443856e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>22.900000</td>\n",
       "      <td>2.928100e+04</td>\n",
       "      <td>2.734800e+04</td>\n",
       "      <td>6.321500e+04</td>\n",
       "      <td>416.000000</td>\n",
       "      <td>8.610000e+02</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.800000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>32.800000</td>\n",
       "      <td>3.928900e+04</td>\n",
       "      <td>4.122700e+04</td>\n",
       "      <td>8.042900e+04</td>\n",
       "      <td>3739.000000</td>\n",
       "      <td>9.224000e+03</td>\n",
       "      <td>2.430000</td>\n",
       "      <td>3.435000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35.300000</td>\n",
       "      <td>5.234100e+04</td>\n",
       "      <td>5.380900e+04</td>\n",
       "      <td>1.067820e+05</td>\n",
       "      <td>5397.000000</td>\n",
       "      <td>1.882200e+04</td>\n",
       "      <td>2.650000</td>\n",
       "      <td>1.378000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>8.664175e+04</td>\n",
       "      <td>8.960400e+04</td>\n",
       "      <td>1.752320e+05</td>\n",
       "      <td>9368.000000</td>\n",
       "      <td>3.397175e+04</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>5.444700e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>70.500000</td>\n",
       "      <td>4.081698e+06</td>\n",
       "      <td>4.468707e+06</td>\n",
       "      <td>8.550405e+06</td>\n",
       "      <td>156961.000000</td>\n",
       "      <td>3.212500e+06</td>\n",
       "      <td>4.980000</td>\n",
       "      <td>3.835726e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Median Age  Male Population  Female Population  Total Population  \\\n",
       "count  2891.000000     2.888000e+03       2.888000e+03      2.891000e+03   \n",
       "mean     35.494881     9.732843e+04       1.017696e+05      1.989668e+05   \n",
       "std       4.401617     2.162999e+05       2.315646e+05      4.475559e+05   \n",
       "min      22.900000     2.928100e+04       2.734800e+04      6.321500e+04   \n",
       "25%      32.800000     3.928900e+04       4.122700e+04      8.042900e+04   \n",
       "50%      35.300000     5.234100e+04       5.380900e+04      1.067820e+05   \n",
       "75%      38.000000     8.664175e+04       8.960400e+04      1.752320e+05   \n",
       "max      70.500000     4.081698e+06       4.468707e+06      8.550405e+06   \n",
       "\n",
       "       Number of Veterans  Foreign-born  Average Household Size         Count  \n",
       "count         2878.000000  2.878000e+03             2875.000000  2.891000e+03  \n",
       "mean          9367.832523  4.065360e+04                2.742543  4.896377e+04  \n",
       "std          13211.219924  1.557491e+05                0.433291  1.443856e+05  \n",
       "min            416.000000  8.610000e+02                2.000000  9.800000e+01  \n",
       "25%           3739.000000  9.224000e+03                2.430000  3.435000e+03  \n",
       "50%           5397.000000  1.882200e+04                2.650000  1.378000e+04  \n",
       "75%           9368.000000  3.397175e+04                2.950000  5.444700e+04  \n",
       "max         156961.000000  3.212500e+06                4.980000  3.835726e+06  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographics.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing the head of the fourth dataset df_airport_codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport_codes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55075 entries, 0 to 55074\n",
      "Data columns (total 12 columns):\n",
      "ident           55075 non-null object\n",
      "type            55075 non-null object\n",
      "name            55075 non-null object\n",
      "elevation_ft    48069 non-null float64\n",
      "continent       27356 non-null object\n",
      "iso_country     54828 non-null object\n",
      "iso_region      55075 non-null object\n",
      "municipality    49399 non-null object\n",
      "gps_code        41030 non-null object\n",
      "iata_code       9189 non-null object\n",
      "local_code      28686 non-null object\n",
      "coordinates     55075 non-null object\n",
      "dtypes: float64(1), object(11)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_airport_codes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describing the fourth dataset df_airport_codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elevation_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48069.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1240.789677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1602.363459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1266.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>205.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>718.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1497.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       elevation_ft\n",
       "count  48069.000000\n",
       "mean    1240.789677\n",
       "std     1602.363459\n",
       "min    -1266.000000\n",
       "25%      205.000000\n",
       "50%      718.000000\n",
       "75%     1497.000000\n",
       "max    22000.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport_codes.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning The First Dataset Cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_immigration_df = spark.read.format('csv').option('header', 'true').load('./Cleaned Data/full_immigration.csv')\n",
    "full_immigration_df.createOrReplaceTempView(\"immigration_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: string (nullable = true)\n",
      " |-- i94yr: string (nullable = true)\n",
      " |-- i94mon: string (nullable = true)\n",
      " |-- i94cit: string (nullable = true)\n",
      " |-- i94res: string (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: string (nullable = true)\n",
      " |-- i94mode: string (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: string (nullable = true)\n",
      " |-- i94bir: string (nullable = true)\n",
      " |-- i94visa: string (nullable = true)\n",
      " |-- count: string (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: string (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: string (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "full_immigration_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|       admnum|fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+\n",
      "|  6.0|2016.0|   4.0| 692.0| 692.0|    XXX|20573.0|   null|   null|   null|  37.0|    2.0|  1.0|    null|    null| null|      T|   null|      U|   null| 1979.0|10282016|  null|  null|   null| 1897628485.0| null|      B2|\n",
      "|  7.0|2016.0|   4.0| 254.0| 276.0|    ATL|20551.0|    1.0|     AL|   null|  25.0|    3.0|  1.0|20130811|     SEO| null|      G|   null|      Y|   null| 1991.0|     D/S|     M|  null|   null| 3736796330.0|00296|      F1|\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|  666643185.0|   93|      B2|\n",
      "| 16.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|  28.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1988.0|09302016|  null|  null|     AA|92468461330.0|00199|      B2|\n",
      "| 17.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|   4.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 2012.0|09302016|  null|  null|     AA|92468463130.0|00199|      B2|\n",
      "| 18.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MI|20555.0|  57.0|    1.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1959.0|09302016|  null|  null|     AZ|92471038030.0|00602|      B1|\n",
      "| 19.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NJ|20558.0|  63.0|    2.0|  1.0|20160401|    null| null|      O|      K|   null|      M| 1953.0|09302016|  null|  null|     AZ|92471399230.0|00602|      B2|\n",
      "| 20.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NJ|20558.0|  57.0|    2.0|  1.0|20160401|    null| null|      O|      K|   null|      M| 1959.0|09302016|  null|  null|     AZ|92471613830.0|00602|      B2|\n",
      "| 21.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NY|20553.0|  46.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1970.0|09302016|  null|  null|     AZ|92470796030.0|00602|      B2|\n",
      "| 22.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NY|20562.0|  48.0|    1.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1968.0|09302016|  null|  null|     AZ|92478489730.0|00608|      B1|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "full_immigration_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the total number of records of full_immigration_df\n",
    "full_immigration_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|count(DISTINCT cicid)|\n",
      "+---------------------+\n",
      "|              3096313|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check for cicid if it unique or not and if unique I will make it a primary key:\n",
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "full_immigration_df.select(countDistinct(\"cicid\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+------------+--------------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|       admnum|fltno|visatype|arrival_date|departure_date|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+------------+--------------+\n",
      "|  6.0|2016.0|   4.0| 692.0| 692.0|    XXX|20573.0|   null|   null|   null|  37.0|    2.0|  1.0|    null|    null| null|      T|   null|      U|   null| 1979.0|10282016|  null|  null|   null| 1897628485.0| null|      B2|  2016-04-29|          null|\n",
      "|  7.0|2016.0|   4.0| 254.0| 276.0|    ATL|20551.0|    1.0|     AL|   null|  25.0|    3.0|  1.0|20130811|     SEO| null|      G|   null|      Y|   null| 1991.0|     D/S|     M|  null|   null| 3736796330.0|00296|      F1|  2016-04-07|          null|\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|  666643185.0|   93|      B2|  2016-04-01|    2016-08-25|\n",
      "| 16.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|  28.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1988.0|09302016|  null|  null|     AA|92468461330.0|00199|      B2|  2016-04-01|    2016-04-23|\n",
      "| 17.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|   4.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 2012.0|09302016|  null|  null|     AA|92468463130.0|00199|      B2|  2016-04-01|    2016-04-23|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Adding a new column 'arrival_date' to the immigration dataset\n",
    "full_immigration_df = spark.sql(\"\"\"\n",
    "    SELECT *, date_add(to_date('1960-01-01'), arrdate) AS arrival_date \n",
    "    FROM immigration_table\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# Adding a new column 'departure_date' to the immigration dataset\n",
    "full_immigration_df = spark.sql(\"\"\"\n",
    "    SELECT *, \n",
    "        CASE \n",
    "            WHEN depdate >= 1.0 THEN date_add(to_date('1960-01-01'), depdate)\n",
    "            WHEN depdate IS NULL THEN NULL\n",
    "            ELSE 'N/A' \n",
    "        END AS departure_date \n",
    "    FROM (\n",
    "        SELECT *, date_add(to_date('1960-01-01'), arrdate) AS arrival_date \n",
    "        FROM immigration_table\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "### Displaying the first five rows of the updated full immigration dataset\n",
    "full_immigration_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+------------+--------------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|       admnum|fltno|visatype|arrival_date|departure_date|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+------------+--------------+\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|  666643185.0|   93|      B2|  2016-04-01|    2016-08-25|\n",
      "| 16.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|  28.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1988.0|09302016|  null|  null|     AA|92468461330.0|00199|      B2|  2016-04-01|    2016-04-23|\n",
      "| 17.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|   4.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 2012.0|09302016|  null|  null|     AA|92468463130.0|00199|      B2|  2016-04-01|    2016-04-23|\n",
      "| 18.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MI|20555.0|  57.0|    1.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1959.0|09302016|  null|  null|     AZ|92471038030.0|00602|      B1|  2016-04-01|    2016-04-11|\n",
      "| 19.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NJ|20558.0|  63.0|    2.0|  1.0|20160401|    null| null|      O|      K|   null|      M| 1953.0|09302016|  null|  null|     AZ|92471399230.0|00602|      B2|  2016-04-01|    2016-04-14|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtering the immigration dataset to only include rows where 'departure_date_2' is greater than or equal to 'arrival_date'\n",
    "full_immigration_df = full_immigration_df.filter(full_immigration_df.departure_date >= full_immigration_df.arrival_date)\n",
    "\n",
    "# Displaying the first 5 rows of the filtered immigration dataset\n",
    "full_immigration_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 2953481\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of rows: {full_immigration_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|i94mode|  count|\n",
      "+-------+-------+\n",
      "|    1.0|2994505|\n",
      "|   null|    239|\n",
      "|    9.0|   8560|\n",
      "|    2.0|  26349|\n",
      "|    3.0|  66660|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Counting the number of rows for each unique value in the 'i94mode' column\n",
    "mode_counts = spark.sql(\"\"\"\n",
    "    SELECT i94mode, COUNT(*) AS count\n",
    "    FROM immigration_table\n",
    "    GROUP BY i94mode\n",
    "\"\"\")\n",
    "\n",
    "# Displaying the result\n",
    "mode_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+------------+--------------+------------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|       admnum|fltno|visatype|arrival_date|departure_date|arrival_mode|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+------------+--------------+------------+\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|  666643185.0|   93|      B2|  2016-04-01|    2016-08-25|Not_reported|\n",
      "| 16.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|  28.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1988.0|09302016|  null|  null|     AA|92468461330.0|00199|      B2|  2016-04-01|    2016-04-23|Not_reported|\n",
      "| 17.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|   4.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 2012.0|09302016|  null|  null|     AA|92468463130.0|00199|      B2|  2016-04-01|    2016-04-23|Not_reported|\n",
      "| 18.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MI|20555.0|  57.0|    1.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1959.0|09302016|  null|  null|     AZ|92471038030.0|00602|      B1|  2016-04-01|    2016-04-11|Not_reported|\n",
      "| 19.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NJ|20558.0|  63.0|    2.0|  1.0|20160401|    null| null|      O|      K|   null|      M| 1953.0|09302016|  null|  null|     AZ|92471399230.0|00602|      B2|  2016-04-01|    2016-04-14|Not_reported|\n",
      "| 20.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NJ|20558.0|  57.0|    2.0|  1.0|20160401|    null| null|      O|      K|   null|      M| 1959.0|09302016|  null|  null|     AZ|92471613830.0|00602|      B2|  2016-04-01|    2016-04-14|Not_reported|\n",
      "| 21.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NY|20553.0|  46.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1970.0|09302016|  null|  null|     AZ|92470796030.0|00602|      B2|  2016-04-01|    2016-04-09|Not_reported|\n",
      "| 22.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NY|20562.0|  48.0|    1.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1968.0|09302016|  null|  null|     AZ|92478489730.0|00608|      B1|  2016-04-01|    2016-04-18|Not_reported|\n",
      "| 23.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NY|20671.0|  52.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1964.0|09302016|  null|  null|     TK|92501394430.0|00001|      B2|  2016-04-01|    2016-08-05|Not_reported|\n",
      "| 24.0|2016.0|   4.0| 101.0| 101.0|    TOR|20545.0|    1.0|     MO|20554.0|  33.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1983.0|09302016|  null|  null|     MQ|92490905030.0|03348|      B2|  2016-04-01|    2016-04-10|Not_reported|\n",
      "| 27.0|2016.0|   4.0| 101.0| 101.0|    BOS|20545.0|    1.0|     MA|20549.0|  58.0|    1.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1958.0|04062016|     M|  null|     LH|92478763830.0|00422|      B1|  2016-04-01|    2016-04-05|Not_reported|\n",
      "| 28.0|2016.0|   4.0| 101.0| 101.0|    ATL|20545.0|    1.0|     MA|20549.0|  56.0|    1.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1960.0|04062016|     F|  null|     LH|92478900330.0|00422|      B1|  2016-04-01|    2016-04-05|Not_reported|\n",
      "| 29.0|2016.0|   4.0| 101.0| 101.0|    ATL|20545.0|    1.0|     MA|20561.0|  62.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1954.0|09302016|     M|  null|     AZ|92503781430.0|00614|      B2|  2016-04-01|    2016-04-17|Not_reported|\n",
      "| 30.0|2016.0|   4.0| 101.0| 101.0|    ATL|20545.0|    1.0|     NJ|20578.0|  49.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1967.0|09302016|     M|  null|     OS|92470209430.0|00089|      B2|  2016-04-01|    2016-05-04|Not_reported|\n",
      "| 31.0|2016.0|   4.0| 101.0| 101.0|    ATL|20545.0|    1.0|     NY|20611.0|  43.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1973.0|09302016|     M|  null|     OS|92471289230.0|00089|      B2|  2016-04-01|    2016-06-06|Not_reported|\n",
      "| 33.0|2016.0|   4.0| 101.0| 101.0|    HOU|20545.0|    1.0|     TX|20554.0|  53.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1963.0|09302016|     F|  null|     TK|92509301630.0|00033|      B2|  2016-04-01|    2016-04-10|Not_reported|\n",
      "| 36.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NJ|20561.0|  37.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1979.0|09302016|     M|  null|     TK|92506258230.0|00001|      B2|  2016-04-01|    2016-04-17|Not_reported|\n",
      "| 37.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NJ|20567.0|  49.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1967.0|09302016|     F|  null|     AZ|92475617830.0|00608|      B2|  2016-04-01|    2016-04-23|Not_reported|\n",
      "| 38.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NY|20575.0|  33.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1983.0|09302016|     M|  null|     AZ|92486092530.0|00608|      B2|  2016-04-01|    2016-05-01|Not_reported|\n",
      "| 39.0|2016.0|   4.0| 101.0| 101.0|    MIA|20545.0|    1.0|     FL|20574.0|  65.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1951.0|09302016|     F|  null|     TK|92507662630.0|00077|      B2|  2016-04-01|    2016-04-30|Not_reported|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+------------+--------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Defining a dictionary to map i94mode values to arrival modes\n",
    "arrival_modes = {1.0: 'Air', 2.0: 'Sea', 3.0: 'Land'}\n",
    "\n",
    "# Adding a new column 'arrival_mode' to the immigration dataset using a UDF\n",
    "def map_arrival_mode(i94mode):\n",
    "    return arrival_modes.get(i94mode, 'Not_reported')\n",
    "\n",
    "map_arrival_mode_udf = udf(map_arrival_mode, StringType())\n",
    "\n",
    "# Adding the 'arrival_mode' column to the 'full_immigration_df' DataFrame\n",
    "full_immigration_df = full_immigration_df.withColumn('arrival_mode', map_arrival_mode_udf('i94mode'))\n",
    "\n",
    "# Displaying the first row of the updated immigration dataset\n",
    "full_immigration_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 2953481\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of rows: {full_immigration_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|i94visa|  count|\n",
      "+-------+-------+\n",
      "|    1.0| 522079|\n",
      "|    2.0|2530868|\n",
      "|    3.0|  43366|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Counting the number of rows for each unique value in the 'i94visa' column\n",
    "visa_counts = spark.sql(\"\"\"\n",
    "    SELECT i94visa, COUNT(*) AS count\n",
    "    FROM immigration_table\n",
    "    GROUP BY i94visa\n",
    "\"\"\")\n",
    "\n",
    "# Displaying the result\n",
    "visa_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+------------+--------------+------------+------------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|       admnum|fltno|visatype|arrival_date|departure_date|arrival_mode|   visa_type|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+------------+--------------+------------+------------+\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|  666643185.0|   93|      B2|  2016-04-01|    2016-08-25|Not_reported|Not_reported|\n",
      "| 16.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|  28.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1988.0|09302016|  null|  null|     AA|92468461330.0|00199|      B2|  2016-04-01|    2016-04-23|Not_reported|Not_reported|\n",
      "| 17.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|   4.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 2012.0|09302016|  null|  null|     AA|92468463130.0|00199|      B2|  2016-04-01|    2016-04-23|Not_reported|Not_reported|\n",
      "| 18.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MI|20555.0|  57.0|    1.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1959.0|09302016|  null|  null|     AZ|92471038030.0|00602|      B1|  2016-04-01|    2016-04-11|Not_reported|Not_reported|\n",
      "| 19.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NJ|20558.0|  63.0|    2.0|  1.0|20160401|    null| null|      O|      K|   null|      M| 1953.0|09302016|  null|  null|     AZ|92471399230.0|00602|      B2|  2016-04-01|    2016-04-14|Not_reported|Not_reported|\n",
      "| 20.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NJ|20558.0|  57.0|    2.0|  1.0|20160401|    null| null|      O|      K|   null|      M| 1959.0|09302016|  null|  null|     AZ|92471613830.0|00602|      B2|  2016-04-01|    2016-04-14|Not_reported|Not_reported|\n",
      "| 21.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NY|20553.0|  46.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1970.0|09302016|  null|  null|     AZ|92470796030.0|00602|      B2|  2016-04-01|    2016-04-09|Not_reported|Not_reported|\n",
      "| 22.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NY|20562.0|  48.0|    1.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1968.0|09302016|  null|  null|     AZ|92478489730.0|00608|      B1|  2016-04-01|    2016-04-18|Not_reported|Not_reported|\n",
      "| 23.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NY|20671.0|  52.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1964.0|09302016|  null|  null|     TK|92501394430.0|00001|      B2|  2016-04-01|    2016-08-05|Not_reported|Not_reported|\n",
      "| 24.0|2016.0|   4.0| 101.0| 101.0|    TOR|20545.0|    1.0|     MO|20554.0|  33.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1983.0|09302016|  null|  null|     MQ|92490905030.0|03348|      B2|  2016-04-01|    2016-04-10|Not_reported|Not_reported|\n",
      "| 27.0|2016.0|   4.0| 101.0| 101.0|    BOS|20545.0|    1.0|     MA|20549.0|  58.0|    1.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1958.0|04062016|     M|  null|     LH|92478763830.0|00422|      B1|  2016-04-01|    2016-04-05|Not_reported|Not_reported|\n",
      "| 28.0|2016.0|   4.0| 101.0| 101.0|    ATL|20545.0|    1.0|     MA|20549.0|  56.0|    1.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1960.0|04062016|     F|  null|     LH|92478900330.0|00422|      B1|  2016-04-01|    2016-04-05|Not_reported|Not_reported|\n",
      "| 29.0|2016.0|   4.0| 101.0| 101.0|    ATL|20545.0|    1.0|     MA|20561.0|  62.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1954.0|09302016|     M|  null|     AZ|92503781430.0|00614|      B2|  2016-04-01|    2016-04-17|Not_reported|Not_reported|\n",
      "| 30.0|2016.0|   4.0| 101.0| 101.0|    ATL|20545.0|    1.0|     NJ|20578.0|  49.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1967.0|09302016|     M|  null|     OS|92470209430.0|00089|      B2|  2016-04-01|    2016-05-04|Not_reported|Not_reported|\n",
      "| 31.0|2016.0|   4.0| 101.0| 101.0|    ATL|20545.0|    1.0|     NY|20611.0|  43.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1973.0|09302016|     M|  null|     OS|92471289230.0|00089|      B2|  2016-04-01|    2016-06-06|Not_reported|Not_reported|\n",
      "| 33.0|2016.0|   4.0| 101.0| 101.0|    HOU|20545.0|    1.0|     TX|20554.0|  53.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1963.0|09302016|     F|  null|     TK|92509301630.0|00033|      B2|  2016-04-01|    2016-04-10|Not_reported|Not_reported|\n",
      "| 36.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NJ|20561.0|  37.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1979.0|09302016|     M|  null|     TK|92506258230.0|00001|      B2|  2016-04-01|    2016-04-17|Not_reported|Not_reported|\n",
      "| 37.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NJ|20567.0|  49.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1967.0|09302016|     F|  null|     AZ|92475617830.0|00608|      B2|  2016-04-01|    2016-04-23|Not_reported|Not_reported|\n",
      "| 38.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NY|20575.0|  33.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1983.0|09302016|     M|  null|     AZ|92486092530.0|00608|      B2|  2016-04-01|    2016-05-01|Not_reported|Not_reported|\n",
      "| 39.0|2016.0|   4.0| 101.0| 101.0|    MIA|20545.0|    1.0|     FL|20574.0|  65.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1951.0|09302016|     F|  null|     TK|92507662630.0|00077|      B2|  2016-04-01|    2016-04-30|Not_reported|Not_reported|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+------------+--------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Defining a dictionary to map i94visa values to visa types\n",
    "visa_types = {1.0: 'Business', 2.0: 'Pleasure', 3.0: 'Student'}\n",
    "\n",
    "def map_visa_type(i94visa):\n",
    "    return visa_types.get(i94visa, 'Not_reported')\n",
    "\n",
    "map_visa_type_udf = udf(map_visa_type, StringType())\n",
    "\n",
    "# Adding the 'visa_type' column to the 'immigration_table' DataFrame\n",
    "full_immigration_df = full_immigration_df\\\n",
    "    .withColumn('visa_type', map_visa_type_udf('i94visa'))\n",
    "\n",
    "# Displaying the first row of the updated immigration dataset\n",
    "full_immigration_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 2953481\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of rows: {full_immigration_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|gender|  count|\n",
      "+------+-------+\n",
      "|     F|1302743|\n",
      "|  null| 414269|\n",
      "|     M|1377224|\n",
      "|     U|    467|\n",
      "|     X|   1610|\n",
      "+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the DataFrame API to group the immigration data by gender and count the number of records\n",
    "gender_counts = spark.sql(\"\"\"\n",
    "    SELECT gender, COUNT(*) AS count\n",
    "    FROM immigration_table\n",
    "    GROUP BY gender\n",
    "\"\"\")\n",
    "# Displaying the gender counts\n",
    "gender_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+------------+--------------+------------+------------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|       admnum|fltno|visatype|arrival_date|departure_date|arrival_mode|   visa_type|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+------------+--------------+------------+------------+\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|  666643185.0|   93|      B2|  2016-04-01|    2016-08-25|Not_reported|Not_reported|\n",
      "| 27.0|2016.0|   4.0| 101.0| 101.0|    BOS|20545.0|    1.0|     MA|20549.0|  58.0|    1.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1958.0|04062016|     M|  null|     LH|92478763830.0|00422|      B1|  2016-04-01|    2016-04-05|Not_reported|Not_reported|\n",
      "| 28.0|2016.0|   4.0| 101.0| 101.0|    ATL|20545.0|    1.0|     MA|20549.0|  56.0|    1.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1960.0|04062016|     F|  null|     LH|92478900330.0|00422|      B1|  2016-04-01|    2016-04-05|Not_reported|Not_reported|\n",
      "| 29.0|2016.0|   4.0| 101.0| 101.0|    ATL|20545.0|    1.0|     MA|20561.0|  62.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1954.0|09302016|     M|  null|     AZ|92503781430.0|00614|      B2|  2016-04-01|    2016-04-17|Not_reported|Not_reported|\n",
      "| 30.0|2016.0|   4.0| 101.0| 101.0|    ATL|20545.0|    1.0|     NJ|20578.0|  49.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1967.0|09302016|     M|  null|     OS|92470209430.0|00089|      B2|  2016-04-01|    2016-05-04|Not_reported|Not_reported|\n",
      "| 31.0|2016.0|   4.0| 101.0| 101.0|    ATL|20545.0|    1.0|     NY|20611.0|  43.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1973.0|09302016|     M|  null|     OS|92471289230.0|00089|      B2|  2016-04-01|    2016-06-06|Not_reported|Not_reported|\n",
      "| 33.0|2016.0|   4.0| 101.0| 101.0|    HOU|20545.0|    1.0|     TX|20554.0|  53.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1963.0|09302016|     F|  null|     TK|92509301630.0|00033|      B2|  2016-04-01|    2016-04-10|Not_reported|Not_reported|\n",
      "| 36.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NJ|20561.0|  37.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1979.0|09302016|     M|  null|     TK|92506258230.0|00001|      B2|  2016-04-01|    2016-04-17|Not_reported|Not_reported|\n",
      "| 37.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NJ|20567.0|  49.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1967.0|09302016|     F|  null|     AZ|92475617830.0|00608|      B2|  2016-04-01|    2016-04-23|Not_reported|Not_reported|\n",
      "| 38.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NY|20575.0|  33.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1983.0|09302016|     M|  null|     AZ|92486092530.0|00608|      B2|  2016-04-01|    2016-05-01|Not_reported|Not_reported|\n",
      "| 39.0|2016.0|   4.0| 101.0| 101.0|    MIA|20545.0|    1.0|     FL|20574.0|  65.0|    2.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1951.0|09302016|     F|  null|     TK|92507662630.0|00077|      B2|  2016-04-01|    2016-04-30|Not_reported|Not_reported|\n",
      "| 40.0|2016.0|   4.0| 101.0| 101.0|    CHI|20545.0|    1.0|     IL|20554.0|  35.0|    1.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1981.0|09302016|     M|  null|     OS|92480562230.0|00065|      B1|  2016-04-01|    2016-04-10|Not_reported|Not_reported|\n",
      "| 41.0|2016.0|   4.0| 101.0| 101.0|    CHI|20545.0|    1.0|     IL|20562.0|  32.0|    1.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1984.0|09302016|     M|  null|     OS|92477809530.0|00065|      B1|  2016-04-01|    2016-04-18|Not_reported|Not_reported|\n",
      "| 42.0|2016.0|   4.0| 101.0| 101.0|    CHI|20545.0|    1.0|     IL|20580.0|  38.0|    1.0|  1.0|20160401|     TIA| null|      G|      O|   null|      M| 1978.0|09302016|     M|  null|     TK|92506217030.0|00005|      B1|  2016-04-01|    2016-05-06|Not_reported|Not_reported|\n",
      "| 47.0|2016.0|   4.0| 101.0| 110.0|    NYC|20545.0|    1.0|     NJ|20665.0|  28.0|    3.0|  1.0|20160401|     HLS| null|      G|      O|   null|      M| 1988.0|     D/S|     F|  null|     AY|92493977730.0|00005|      F1|  2016-04-01|    2016-07-30|Not_reported|Not_reported|\n",
      "| 48.0|2016.0|   4.0| 101.0| 117.0|    NYC|20545.0|    1.0|     NY|20572.0|  68.0|    2.0|  1.0|20160401|     FLR| null|      G|      O|   null|      M| 1948.0|09302016|     M|  null|     AA|92473604830.0|00199|      B2|  2016-04-01|    2016-04-28|Not_reported|Not_reported|\n",
      "| 49.0|2016.0|   4.0| 101.0| 117.0|    NYC|20545.0|    1.0|     NY|20572.0|  61.0|    2.0|  1.0|20160401|     FLR| null|      G|      O|   null|      M| 1955.0|09302016|     F|  null|     AA|92473424130.0|00199|      B2|  2016-04-01|    2016-04-28|Not_reported|Not_reported|\n",
      "| 50.0|2016.0|   4.0| 101.0| 117.0|    NYC|20545.0|    1.0|     MI|20563.0|  41.0|    2.0|  1.0|20160401|     NPL| null|      G|      O|   null|      M| 1975.0|09302016|     F|  null|     AZ|92503675030.0|00610|      B2|  2016-04-01|    2016-04-19|Not_reported|Not_reported|\n",
      "| 51.0|2016.0|   4.0| 101.0| 117.0|    MIA|20545.0|    1.0|     FL|20555.0|  45.0|    2.0|  1.0|20160401|     RME| null|      G|      O|   null|      M| 1971.0|09302016|     F|  null|     AA|92486267630.0|00207|      B2|  2016-04-01|    2016-04-11|Not_reported|Not_reported|\n",
      "| 52.0|2016.0|   4.0| 101.0| 112.0|    NYC|20545.0|    1.0|     NY|20558.0|  54.0|    2.0|  1.0|20160401|     BRL| null|      G|      O|   null|      M| 1962.0|09302016|     M|  null|     AB|92469910630.0|07450|      B2|  2016-04-01|    2016-04-14|Not_reported|Not_reported|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+------------+--------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def clean_full_immigration_df_gender(full_immigration_df):\n",
    "    # Filtering the immigration data by gender using the DataFrame API\n",
    "    full_immigration_df = full_immigration_df \\\n",
    "        .filter(full_immigration_df.gender.isin(['M', 'F']))\n",
    "\n",
    "    # Creating a temporary view for the filtered data\n",
    "    full_immigration_df.createOrReplaceTempView('immigration_table')\n",
    "\n",
    "    # return the cleaned data:\n",
    "    return full_immigration_df\n",
    "    \n",
    "full_immigration_df = clean_full_immigration_df_gender(full_immigration_df)\n",
    "\n",
    "# Displaying the first row of the filtered data\n",
    "full_immigration_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 2544951\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of rows: {full_immigration_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+-----------------------+---------------------------+--------+------------+--------------+------------+-------------+----+------------+-----+----------+------+-------+-------------+----------+\n",
      "|cicid|  year|month|immigrant_birth_country|immigrant_residence_country|adm_port|arrival_date|departure_date|arrival_mode|arrival_state| age|   visa_type|count|birth_year|gender|airline|admission_num|flight_num|\n",
      "+-----+------+-----+-----------------------+---------------------------+--------+------------+--------------+------------+-------------+----+------------+-----+----------+------+-------+-------------+----------+\n",
      "| 15.0|2016.0|  4.0|                  101.0|                      101.0|     WAS|  2016-04-01|    2016-08-25|Not_reported|           MI|55.0|Not_reported|  1.0|    1961.0|     M|     OS|  666643185.0|        93|\n",
      "| 27.0|2016.0|  4.0|                  101.0|                      101.0|     BOS|  2016-04-01|    2016-04-05|Not_reported|           MA|58.0|Not_reported|  1.0|    1958.0|     M|     LH|92478763830.0|     00422|\n",
      "| 28.0|2016.0|  4.0|                  101.0|                      101.0|     ATL|  2016-04-01|    2016-04-05|Not_reported|           MA|56.0|Not_reported|  1.0|    1960.0|     F|     LH|92478900330.0|     00422|\n",
      "| 29.0|2016.0|  4.0|                  101.0|                      101.0|     ATL|  2016-04-01|    2016-04-17|Not_reported|           MA|62.0|Not_reported|  1.0|    1954.0|     M|     AZ|92503781430.0|     00614|\n",
      "| 30.0|2016.0|  4.0|                  101.0|                      101.0|     ATL|  2016-04-01|    2016-05-04|Not_reported|           NJ|49.0|Not_reported|  1.0|    1967.0|     M|     OS|92470209430.0|     00089|\n",
      "| 31.0|2016.0|  4.0|                  101.0|                      101.0|     ATL|  2016-04-01|    2016-06-06|Not_reported|           NY|43.0|Not_reported|  1.0|    1973.0|     M|     OS|92471289230.0|     00089|\n",
      "| 33.0|2016.0|  4.0|                  101.0|                      101.0|     HOU|  2016-04-01|    2016-04-10|Not_reported|           TX|53.0|Not_reported|  1.0|    1963.0|     F|     TK|92509301630.0|     00033|\n",
      "| 36.0|2016.0|  4.0|                  101.0|                      101.0|     NYC|  2016-04-01|    2016-04-17|Not_reported|           NJ|37.0|Not_reported|  1.0|    1979.0|     M|     TK|92506258230.0|     00001|\n",
      "| 37.0|2016.0|  4.0|                  101.0|                      101.0|     NYC|  2016-04-01|    2016-04-23|Not_reported|           NJ|49.0|Not_reported|  1.0|    1967.0|     F|     AZ|92475617830.0|     00608|\n",
      "| 38.0|2016.0|  4.0|                  101.0|                      101.0|     NYC|  2016-04-01|    2016-05-01|Not_reported|           NY|33.0|Not_reported|  1.0|    1983.0|     M|     AZ|92486092530.0|     00608|\n",
      "+-----+------+-----+-----------------------+---------------------------+--------+------------+--------------+------------+-------------+----+------------+-----+----------+------+-------+-------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def clean_full_immigration_df(full_immigration_df):    \n",
    "    # Selecting and renaming columns from the immigration data using the DataFrame API\n",
    "    cols = ['cicid', 'year', 'month', 'immigrant_birth_country', 'immigrant_residence_country', 'adm_port',\n",
    "            'arrival_date', 'departure_date', 'arrival_mode', 'arrival_state', 'age', 'visa_type', 'count',\n",
    "            'birth_year', 'gender', 'airline', 'admission_num', 'flight_num']\n",
    "    full_immigration_df = full_immigration_df.select(\n",
    "        col('cicid'), col('i94yr').alias('year'), col('i94mon').alias('month'),\n",
    "        col('i94cit').alias('immigrant_birth_country'), col('i94res').alias('immigrant_residence_country'),\n",
    "        col('i94port').alias('adm_port'), col('arrival_date'), col('departure_date'), col('arrival_mode'),\n",
    "        col('i94addr').alias('arrival_state'), col('i94bir').alias('age'), col('visa_type'), col('count'),\n",
    "        col('biryear').alias('birth_year'), col('gender'), col('airline'), col('admnum').alias('admission_num'),\n",
    "        col('fltno').alias('flight_num')\n",
    "    ).toDF(*cols)\n",
    "    # return the cleaned data:\n",
    "    return full_immigration_df\n",
    "    \n",
    "full_immigration_df = clean_full_immigration_df(full_immigration_df)\n",
    "# Displaying the selected columns from the immigration data\n",
    "full_immigration_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 2544951\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of rows: {full_immigration_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8599212 entries, 0 to 8599211\n",
      "Data columns (total 7 columns):\n",
      "dt                               object\n",
      "AverageTemperature               float64\n",
      "AverageTemperatureUncertainty    float64\n",
      "City                             object\n",
      "Country                          object\n",
      "Latitude                         object\n",
      "Longitude                        object\n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 459.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dt                                    0\n",
       "AverageTemperature               364130\n",
       "AverageTemperatureUncertainty    364130\n",
       "City                                  0\n",
       "Country                               0\n",
       "Latitude                              0\n",
       "Longitude                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47555</th>\n",
       "      <td>1820-01-01</td>\n",
       "      <td>2.101</td>\n",
       "      <td>3.217</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47556</th>\n",
       "      <td>1820-02-01</td>\n",
       "      <td>6.926</td>\n",
       "      <td>2.853</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47557</th>\n",
       "      <td>1820-03-01</td>\n",
       "      <td>10.767</td>\n",
       "      <td>2.395</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47558</th>\n",
       "      <td>1820-04-01</td>\n",
       "      <td>17.989</td>\n",
       "      <td>2.202</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47559</th>\n",
       "      <td>1820-05-01</td>\n",
       "      <td>21.809</td>\n",
       "      <td>2.036</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47560</th>\n",
       "      <td>1820-06-01</td>\n",
       "      <td>25.682</td>\n",
       "      <td>2.008</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47561</th>\n",
       "      <td>1820-07-01</td>\n",
       "      <td>26.268</td>\n",
       "      <td>1.802</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47562</th>\n",
       "      <td>1820-08-01</td>\n",
       "      <td>25.048</td>\n",
       "      <td>1.895</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47563</th>\n",
       "      <td>1820-09-01</td>\n",
       "      <td>22.435</td>\n",
       "      <td>2.216</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47564</th>\n",
       "      <td>1820-10-01</td>\n",
       "      <td>15.830</td>\n",
       "      <td>2.169</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              dt  AverageTemperature  AverageTemperatureUncertainty     City  \\\n",
       "47555 1820-01-01               2.101                          3.217  Abilene   \n",
       "47556 1820-02-01               6.926                          2.853  Abilene   \n",
       "47557 1820-03-01              10.767                          2.395  Abilene   \n",
       "47558 1820-04-01              17.989                          2.202  Abilene   \n",
       "47559 1820-05-01              21.809                          2.036  Abilene   \n",
       "47560 1820-06-01              25.682                          2.008  Abilene   \n",
       "47561 1820-07-01              26.268                          1.802  Abilene   \n",
       "47562 1820-08-01              25.048                          1.895  Abilene   \n",
       "47563 1820-09-01              22.435                          2.216  Abilene   \n",
       "47564 1820-10-01              15.830                          2.169  Abilene   \n",
       "\n",
       "             Country Latitude Longitude  \n",
       "47555  United States   32.95N   100.53W  \n",
       "47556  United States   32.95N   100.53W  \n",
       "47557  United States   32.95N   100.53W  \n",
       "47558  United States   32.95N   100.53W  \n",
       "47559  United States   32.95N   100.53W  \n",
       "47560  United States   32.95N   100.53W  \n",
       "47561  United States   32.95N   100.53W  \n",
       "47562  United States   32.95N   100.53W  \n",
       "47563  United States   32.95N   100.53W  \n",
       "47564  United States   32.95N   100.53W  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_df_temp(df_temp):\n",
    "    # Remove rows with missing temperature values\n",
    "    df_temp = df_temp.dropna()\n",
    "\n",
    "    # filter the  for the United States to make it useful with our immigration data\n",
    "    df_temp = df_temp[df_temp['Country']=='United States']\n",
    "\n",
    "    # Convert dt to datetime\n",
    "    df_temp.dt = pd.to_datetime(df_temp.dt)\n",
    "    # return the cleaned data:\n",
    "    return df_temp\n",
    "\n",
    "df_temp = clean_df_temp(df_temp)\n",
    "df_temp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.to_csv('./Cleaned Data/df_temp.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Third dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Peoria</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>33.1</td>\n",
       "      <td>56229.0</td>\n",
       "      <td>62432.0</td>\n",
       "      <td>118661</td>\n",
       "      <td>6634.0</td>\n",
       "      <td>7517.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>IL</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>1343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Avondale</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>29.1</td>\n",
       "      <td>38712.0</td>\n",
       "      <td>41971.0</td>\n",
       "      <td>80683</td>\n",
       "      <td>4815.0</td>\n",
       "      <td>8355.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>11592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West Covina</td>\n",
       "      <td>California</td>\n",
       "      <td>39.8</td>\n",
       "      <td>51629.0</td>\n",
       "      <td>56860.0</td>\n",
       "      <td>108489</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>37038.0</td>\n",
       "      <td>3.56</td>\n",
       "      <td>CA</td>\n",
       "      <td>Asian</td>\n",
       "      <td>32716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>O'Fallon</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>36.0</td>\n",
       "      <td>41762.0</td>\n",
       "      <td>43270.0</td>\n",
       "      <td>85032</td>\n",
       "      <td>5783.0</td>\n",
       "      <td>3269.0</td>\n",
       "      <td>2.77</td>\n",
       "      <td>MO</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>2583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>High Point</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>35.5</td>\n",
       "      <td>51751.0</td>\n",
       "      <td>58077.0</td>\n",
       "      <td>109828</td>\n",
       "      <td>5204.0</td>\n",
       "      <td>16315.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>NC</td>\n",
       "      <td>Asian</td>\n",
       "      <td>11060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City           State  Median Age  Male Population  \\\n",
       "0     Silver Spring        Maryland        33.8          40601.0   \n",
       "1            Quincy   Massachusetts        41.0          44129.0   \n",
       "2            Hoover         Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga      California        34.5          88127.0   \n",
       "4            Newark      New Jersey        34.6         138040.0   \n",
       "5            Peoria        Illinois        33.1          56229.0   \n",
       "6          Avondale         Arizona        29.1          38712.0   \n",
       "7       West Covina      California        39.8          51629.0   \n",
       "8          O'Fallon        Missouri        36.0          41762.0   \n",
       "9        High Point  North Carolina        35.5          51751.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "5            62432.0            118661              6634.0        7517.0   \n",
       "6            41971.0             80683              4815.0        8355.0   \n",
       "7            56860.0            108489              3800.0       37038.0   \n",
       "8            43270.0             85032              5783.0        3269.0   \n",
       "9            58077.0            109828              5204.0       16315.0   \n",
       "\n",
       "   Average Household Size State Code                               Race  Count  \n",
       "0                    2.60         MD                 Hispanic or Latino  25924  \n",
       "1                    2.39         MA                              White  58723  \n",
       "2                    2.58         AL                              Asian   4759  \n",
       "3                    3.18         CA          Black or African-American  24437  \n",
       "4                    2.73         NJ                              White  76402  \n",
       "5                    2.40         IL  American Indian and Alaska Native   1343  \n",
       "6                    3.18         AZ          Black or African-American  11592  \n",
       "7                    3.56         CA                              Asian  32716  \n",
       "8                    2.77         MO                 Hispanic or Latino   2583  \n",
       "9                    2.65         NC                              Asian  11060  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_df_demographics(df_demographics):\n",
    "    # Remove rows with missing values\n",
    "    df_demographics = df_demographics.dropna().reset_index(drop=True)\n",
    "\n",
    "    # Convert numeric columns to appropriate data types\n",
    "    numeric_columns = [\"Median Age\", \"Male Population\", \"Female Population\", \"Total Population\", \n",
    "                       \"Number of Veterans\", \"Foreign-born\", \"Average Household Size\", \"Count\"]\n",
    "    df_demographics[numeric_columns] = df_demographics[numeric_columns].apply(pd.to_numeric)\n",
    "\n",
    "    # Convert categorical columns to appropriate data types\n",
    "    categorical_columns = [\"City\", \"State\", \"State Code\", \"Race\"]\n",
    "    df_demographics[categorical_columns] = df_demographics[categorical_columns].astype(\"category\")\n",
    "    # return the cleaned data:\n",
    "    return df_demographics\n",
    "\n",
    "df_demographics = clean_df_demographics(df_demographics)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "df_demographics.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demographics.to_csv('./Cleaned Data/df_demographics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airport_codes = pd.read_csv(\"./airport-codes_csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55075, 12)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport_codes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ident               0\n",
       "type                0\n",
       "name                0\n",
       "elevation_ft     7006\n",
       "continent       27719\n",
       "iso_country       247\n",
       "iso_region          0\n",
       "municipality     5676\n",
       "gps_code        14045\n",
       "iata_code       45886\n",
       "local_code      26389\n",
       "coordinates         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport_codes.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2019, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07FA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Ocean Reef Club Airport</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-FL</td>\n",
       "      <td>Key Largo</td>\n",
       "      <td>07FA</td>\n",
       "      <td>OCA</td>\n",
       "      <td>07FA</td>\n",
       "      <td>-80.274803</td>\n",
       "      <td>25.325399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Pilot Station Airport</td>\n",
       "      <td>305.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Pilot Station</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PQS</td>\n",
       "      <td>0AK</td>\n",
       "      <td>-162.899994</td>\n",
       "      <td>61.934601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0CO2</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Crested Butte Airpark</td>\n",
       "      <td>8980.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CO</td>\n",
       "      <td>Crested Butte</td>\n",
       "      <td>0CO2</td>\n",
       "      <td>CSE</td>\n",
       "      <td>0CO2</td>\n",
       "      <td>-106.928341</td>\n",
       "      <td>38.851918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0TE7</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>LBJ Ranch Airport</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>Johnson City</td>\n",
       "      <td>0TE7</td>\n",
       "      <td>JCY</td>\n",
       "      <td>0TE7</td>\n",
       "      <td>-98.622498</td>\n",
       "      <td>30.251801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13MA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Metropolitan Airport</td>\n",
       "      <td>418.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-MA</td>\n",
       "      <td>Palmer</td>\n",
       "      <td>13MA</td>\n",
       "      <td>PMX</td>\n",
       "      <td>13MA</td>\n",
       "      <td>-72.311401</td>\n",
       "      <td>42.223301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13Z</td>\n",
       "      <td>seaplane_base</td>\n",
       "      <td>Loring Seaplane Base</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Loring</td>\n",
       "      <td>13Z</td>\n",
       "      <td>WLR</td>\n",
       "      <td>13Z</td>\n",
       "      <td>-131.636993</td>\n",
       "      <td>55.601299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16A</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Nunapitchuk Airport</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Nunapitchuk</td>\n",
       "      <td>PPIT</td>\n",
       "      <td>NUP</td>\n",
       "      <td>16A</td>\n",
       "      <td>-162.440454</td>\n",
       "      <td>60.905591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16K</td>\n",
       "      <td>seaplane_base</td>\n",
       "      <td>Port Alice Seaplane Base</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Port Alice</td>\n",
       "      <td>16K</td>\n",
       "      <td>PTC</td>\n",
       "      <td>16K</td>\n",
       "      <td>-133.597000</td>\n",
       "      <td>55.803000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Icy Bay Airport</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Icy Bay</td>\n",
       "      <td>19AK</td>\n",
       "      <td>ICY</td>\n",
       "      <td>19AK</td>\n",
       "      <td>-141.662003</td>\n",
       "      <td>59.969002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19P</td>\n",
       "      <td>seaplane_base</td>\n",
       "      <td>Port Protection Seaplane Base</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Port Protection</td>\n",
       "      <td>19P</td>\n",
       "      <td>PPV</td>\n",
       "      <td>19P</td>\n",
       "      <td>-133.610001</td>\n",
       "      <td>56.328800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ident           type                           name  elevation_ft  \\\n",
       "1   07FA  small_airport        Ocean Reef Club Airport           8.0   \n",
       "2    0AK  small_airport          Pilot Station Airport         305.0   \n",
       "3   0CO2  small_airport          Crested Butte Airpark        8980.0   \n",
       "4   0TE7  small_airport              LBJ Ranch Airport        1515.0   \n",
       "5   13MA  small_airport           Metropolitan Airport         418.0   \n",
       "6    13Z  seaplane_base           Loring Seaplane Base           0.0   \n",
       "7    16A  small_airport            Nunapitchuk Airport          12.0   \n",
       "8    16K  seaplane_base       Port Alice Seaplane Base           0.0   \n",
       "9   19AK  small_airport                Icy Bay Airport          50.0   \n",
       "10   19P  seaplane_base  Port Protection Seaplane Base           0.0   \n",
       "\n",
       "   continent iso_country iso_region     municipality gps_code iata_code  \\\n",
       "1        NaN          US      US-FL        Key Largo     07FA       OCA   \n",
       "2        NaN          US      US-AK    Pilot Station      NaN       PQS   \n",
       "3        NaN          US      US-CO    Crested Butte     0CO2       CSE   \n",
       "4        NaN          US      US-TX     Johnson City     0TE7       JCY   \n",
       "5        NaN          US      US-MA           Palmer     13MA       PMX   \n",
       "6        NaN          US      US-AK           Loring      13Z       WLR   \n",
       "7        NaN          US      US-AK      Nunapitchuk     PPIT       NUP   \n",
       "8        NaN          US      US-AK       Port Alice      16K       PTC   \n",
       "9        NaN          US      US-AK          Icy Bay     19AK       ICY   \n",
       "10       NaN          US      US-AK  Port Protection      19P       PPV   \n",
       "\n",
       "   local_code   longitude   latitude  \n",
       "1        07FA  -80.274803  25.325399  \n",
       "2         0AK -162.899994  61.934601  \n",
       "3        0CO2 -106.928341  38.851918  \n",
       "4        0TE7  -98.622498  30.251801  \n",
       "5        13MA  -72.311401  42.223301  \n",
       "6         13Z -131.636993  55.601299  \n",
       "7         16A -162.440454  60.905591  \n",
       "8         16K -133.597000  55.803000  \n",
       "9        19AK -141.662003  59.969002  \n",
       "10        19P -133.610001  56.328800  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_df_airport_codes(df_airport_codes):\n",
    "    # Remove rows with missing values in the 'iata_code' column\n",
    "    df_airport_codes = df_airport_codes.dropna(subset=['iata_code']).reset_index(drop=True)\n",
    "\n",
    "    # Convert numeric columns to appropriate data types\n",
    "    numeric_columns = [\"elevation_ft\"]\n",
    "    df_airport_codes[numeric_columns] = df_airport_codes[numeric_columns].apply(pd.to_numeric)\n",
    "\n",
    "    # Convert categorical columns to appropriate data types\n",
    "    categorical_columns = [\"ident\", \"type\", \"name\", \"continent\", \"iso_country\", \"iso_region\", \"municipality\", \"gps_code\", \"iata_code\", \"local_code\"]\n",
    "    df_airport_codes[categorical_columns] = df_airport_codes[categorical_columns].astype(\"category\")\n",
    "\n",
    "    # Split the 'coordinates' column into separate 'latitude' and 'longitude' columns\n",
    "    df_airport_codes[[\"longitude\", \"latitude\"]] = df_airport_codes[\"coordinates\"].str.split(\",\", expand=True).apply(pd.to_numeric)\n",
    "\n",
    "    # filter the  for the United States to make it useful with our immigration data\n",
    "    df_airport_codes = df_airport_codes[df_airport_codes['iso_country'] == 'US']\n",
    "\n",
    "    # Drop the original 'coordinates' column\n",
    "    df_airport_codes = df_airport_codes.drop(columns=[\"coordinates\"])\n",
    "    # return the cleaned data:\n",
    "    return df_airport_codes\n",
    "    \n",
    "df_airport_codes = clean_df_airport_codes(df_airport_codes)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(df_airport_codes.shape)\n",
    "df_airport_codes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2019, 13)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport_codes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ident              0\n",
       "type               0\n",
       "name               0\n",
       "elevation_ft      34\n",
       "continent       2019\n",
       "iso_country        0\n",
       "iso_region         0\n",
       "municipality       6\n",
       "gps_code          81\n",
       "iata_code          0\n",
       "local_code        50\n",
       "longitude          0\n",
       "latitude           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport_codes.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airport_codes = df_airport_codes.drop(columns=[\"continent\"])\n",
    "df_airport_codes.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07FA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Ocean Reef Club Airport</td>\n",
       "      <td>8.0</td>\n",
       "      <td>US</td>\n",
       "      <td>US-FL</td>\n",
       "      <td>Key Largo</td>\n",
       "      <td>07FA</td>\n",
       "      <td>OCA</td>\n",
       "      <td>07FA</td>\n",
       "      <td>-80.274803</td>\n",
       "      <td>25.325399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0CO2</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Crested Butte Airpark</td>\n",
       "      <td>8980.0</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CO</td>\n",
       "      <td>Crested Butte</td>\n",
       "      <td>0CO2</td>\n",
       "      <td>CSE</td>\n",
       "      <td>0CO2</td>\n",
       "      <td>-106.928341</td>\n",
       "      <td>38.851918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0TE7</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>LBJ Ranch Airport</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>Johnson City</td>\n",
       "      <td>0TE7</td>\n",
       "      <td>JCY</td>\n",
       "      <td>0TE7</td>\n",
       "      <td>-98.622498</td>\n",
       "      <td>30.251801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13MA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Metropolitan Airport</td>\n",
       "      <td>418.0</td>\n",
       "      <td>US</td>\n",
       "      <td>US-MA</td>\n",
       "      <td>Palmer</td>\n",
       "      <td>13MA</td>\n",
       "      <td>PMX</td>\n",
       "      <td>13MA</td>\n",
       "      <td>-72.311401</td>\n",
       "      <td>42.223301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13Z</td>\n",
       "      <td>seaplane_base</td>\n",
       "      <td>Loring Seaplane Base</td>\n",
       "      <td>0.0</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Loring</td>\n",
       "      <td>13Z</td>\n",
       "      <td>WLR</td>\n",
       "      <td>13Z</td>\n",
       "      <td>-131.636993</td>\n",
       "      <td>55.601299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16A</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Nunapitchuk Airport</td>\n",
       "      <td>12.0</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Nunapitchuk</td>\n",
       "      <td>PPIT</td>\n",
       "      <td>NUP</td>\n",
       "      <td>16A</td>\n",
       "      <td>-162.440454</td>\n",
       "      <td>60.905591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16K</td>\n",
       "      <td>seaplane_base</td>\n",
       "      <td>Port Alice Seaplane Base</td>\n",
       "      <td>0.0</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Port Alice</td>\n",
       "      <td>16K</td>\n",
       "      <td>PTC</td>\n",
       "      <td>16K</td>\n",
       "      <td>-133.597000</td>\n",
       "      <td>55.803000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Icy Bay Airport</td>\n",
       "      <td>50.0</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Icy Bay</td>\n",
       "      <td>19AK</td>\n",
       "      <td>ICY</td>\n",
       "      <td>19AK</td>\n",
       "      <td>-141.662003</td>\n",
       "      <td>59.969002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19P</td>\n",
       "      <td>seaplane_base</td>\n",
       "      <td>Port Protection Seaplane Base</td>\n",
       "      <td>0.0</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Port Protection</td>\n",
       "      <td>19P</td>\n",
       "      <td>PPV</td>\n",
       "      <td>19P</td>\n",
       "      <td>-133.610001</td>\n",
       "      <td>56.328800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1KC</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Kalakaket Creek AS Airport</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Kalakaket Creek</td>\n",
       "      <td>1KC</td>\n",
       "      <td>KKK</td>\n",
       "      <td>1KC</td>\n",
       "      <td>-156.820393</td>\n",
       "      <td>64.416626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ident           type                           name  elevation_ft  \\\n",
       "1   07FA  small_airport        Ocean Reef Club Airport           8.0   \n",
       "3   0CO2  small_airport          Crested Butte Airpark        8980.0   \n",
       "4   0TE7  small_airport              LBJ Ranch Airport        1515.0   \n",
       "5   13MA  small_airport           Metropolitan Airport         418.0   \n",
       "6    13Z  seaplane_base           Loring Seaplane Base           0.0   \n",
       "7    16A  small_airport            Nunapitchuk Airport          12.0   \n",
       "8    16K  seaplane_base       Port Alice Seaplane Base           0.0   \n",
       "9   19AK  small_airport                Icy Bay Airport          50.0   \n",
       "10   19P  seaplane_base  Port Protection Seaplane Base           0.0   \n",
       "11   1KC  small_airport     Kalakaket Creek AS Airport        1598.0   \n",
       "\n",
       "   iso_country iso_region     municipality gps_code iata_code local_code  \\\n",
       "1           US      US-FL        Key Largo     07FA       OCA       07FA   \n",
       "3           US      US-CO    Crested Butte     0CO2       CSE       0CO2   \n",
       "4           US      US-TX     Johnson City     0TE7       JCY       0TE7   \n",
       "5           US      US-MA           Palmer     13MA       PMX       13MA   \n",
       "6           US      US-AK           Loring      13Z       WLR        13Z   \n",
       "7           US      US-AK      Nunapitchuk     PPIT       NUP        16A   \n",
       "8           US      US-AK       Port Alice      16K       PTC        16K   \n",
       "9           US      US-AK          Icy Bay     19AK       ICY       19AK   \n",
       "10          US      US-AK  Port Protection      19P       PPV        19P   \n",
       "11          US      US-AK  Kalakaket Creek      1KC       KKK        1KC   \n",
       "\n",
       "     longitude   latitude  \n",
       "1   -80.274803  25.325399  \n",
       "3  -106.928341  38.851918  \n",
       "4   -98.622498  30.251801  \n",
       "5   -72.311401  42.223301  \n",
       "6  -131.636993  55.601299  \n",
       "7  -162.440454  60.905591  \n",
       "8  -133.597000  55.803000  \n",
       "9  -141.662003  59.969002  \n",
       "10 -133.610001  56.328800  \n",
       "11 -156.820393  64.416626  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport_codes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airport_codes.to_csv('./Cleaned Data/df_airport_codes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entities:\n",
    "- Immigration fact table with columns:\n",
    "    - cicid (double)\n",
    "    - year (double)\n",
    "    - month (double)\n",
    "    - immigrant_birth_country (double)\n",
    "    - immigrant_residence_country (double)\n",
    "    - adm_port (string)\n",
    "    - arrival_date (double)\n",
    "    - departure_date (double)\n",
    "    - arrival_mode (double)\n",
    "    - arrival_state (string)\n",
    "    - age (double)\n",
    "    - visa_type (double)\n",
    "    - count (double)\n",
    "    - birth_year (double)\n",
    "    - gender (string)\n",
    "    - airline (string)\n",
    "    - admission_num (double)\n",
    "    - flight_num (string)\n",
    "    - visatype (string)\n",
    "- Temperature dimension table with columns:\n",
    "    - dt (date)\n",
    "    - AverageTemperature (double)\n",
    "    - City (string)\n",
    "    - Country (string)\n",
    "- Demographic dimension table with columns:\n",
    "    - City (string)\n",
    "    - State (string)\n",
    "    - median_age (double)\n",
    "    - male_population (integer)\n",
    "    - female_population (integer)\n",
    "    - total_population (integer)\n",
    "    - num_veterans (integer)\n",
    "    - num_foreign_born (integer)\n",
    "    - avg_household_size (double)\n",
    "    - state_code (string)\n",
    "    - Race (string)\n",
    "    - Count (integer)\n",
    "- Airport dimension table with columns:\n",
    "    - ident (string)\n",
    "    - type (string)\n",
    "    - name (string)\n",
    "    - elevation_ft (double)\n",
    "    - iso_country (string)\n",
    "    - iso_region (string)\n",
    "    - municipality (string)\n",
    "    - gps_code (string)\n",
    "    - iata_code (string)\n",
    "    - local_code (string)\n",
    "    - longitude (double)\n",
    "    - latitude (double)\n",
    "\n",
    "Relationships:\n",
    "- The Immigration fact table is related to the Temperature dimension table and the Demographic dimension table through the City and State columns respectively.\n",
    "- The Immigration fact table is related to the Airport dimension table through the adm_port column representing the airport code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "\n",
    "***1. Run the create_tables.py script to generate the necessary tables in the database.***\n",
    "\n",
    "***2. Combine the data from the city and airports tables using a join operation.***\n",
    "\n",
    "***3. Populate the tables with the relevant data.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark df of all the tables\n",
    "file_paths = [\n",
    "    './Cleaned Data/full_immigration.csv',\n",
    "    './Cleaned Data/df_temp.csv',\n",
    "    './Cleaned Data/df_demographics.csv',\n",
    "    './Cleaned Data/df_airport_codes.csv',\n",
    "\n",
    "]\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    df = spark.read.format('csv').option('header', 'true').load(file_path)\n",
    "    dataframes.append(df)\n",
    "\n",
    "spark_i94, spark_temp, spark_airport, spark_demographics = dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: string (nullable = true)\n",
      " |-- i94yr: string (nullable = true)\n",
      " |-- i94mon: string (nullable = true)\n",
      " |-- i94cit: string (nullable = true)\n",
      " |-- i94res: string (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: string (nullable = true)\n",
      " |-- i94mode: string (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: string (nullable = true)\n",
      " |-- i94bir: string (nullable = true)\n",
      " |-- i94visa: string (nullable = true)\n",
      " |-- count: string (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: string (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: string (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- dt: string (nullable = true)\n",
      " |-- AverageTemperature: string (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: string (nullable = true)\n",
      " |-- Male Population: string (nullable = true)\n",
      " |-- Female Population: string (nullable = true)\n",
      " |-- Total Population: string (nullable = true)\n",
      " |-- Number of Veterans: string (nullable = true)\n",
      " |-- Foreign-born: string (nullable = true)\n",
      " |-- Average Household Size: string (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- longitude: string (nullable = true)\n",
      " |-- latitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_names = [\"i94\", \"temperature\", \"airport\", \"demographics\"]\n",
    "for dataframe, name in zip(dataframes, table_names):\n",
    "    dataframe.createOrReplaceTempView(name)\n",
    "    dataframe.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"immigration_data_pipeline\").getOrCreate()\n",
    "\n",
    "# Load the immigration data\n",
    "immigration_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .load('./Cleaned Data/full_immigration.csv')\n",
    "\n",
    "# Select relevant columns and rename them from immigration_df:\n",
    "immigration_fact = immigration_df.select(\n",
    "    col(\"cicid\"),\n",
    "    col(\"i94yr\").alias(\"year\"),\n",
    "    col(\"i94mon\").alias(\"month\"),\n",
    "    col(\"i94cit\").alias(\"immigrant_birth_country\"),\n",
    "    col(\"i94res\").alias(\"immigrant_residence_country\"),\n",
    "    col(\"i94port\").alias(\"adm_port\"),\n",
    "    col(\"arrdate\").alias(\"arrival_date\"),\n",
    "    col(\"depdate\").alias(\"departure_date\"),\n",
    "    col(\"i94mode\").alias(\"arrival_mode\"),\n",
    "    col(\"i94addr\").alias(\"arrival_state\"),\n",
    "    col(\"i94bir\").alias(\"age\"),\n",
    "    col(\"i94visa\").alias(\"visa_type\"),\n",
    "    col(\"count\"),\n",
    "    col(\"biryear\").alias(\"birth_year\"),\n",
    "    col(\"gender\"),\n",
    "    col(\"airline\"),\n",
    "    col(\"admnum\").alias(\"admission_num\"),\n",
    "    col(\"fltno\").alias(\"flight_num\"),\n",
    "    col(\"visatype\")\n",
    ")\n",
    "\n",
    "# Load the temperature data\n",
    "temperature_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .load('./Cleaned Data/df_temp.csv')\n",
    "\n",
    "# Select relevant columns and filter for data in the United States from temperature_df:\n",
    "temperature_dim = temperature_df.select(\n",
    "    col(\"dt\"),\n",
    "    col(\"AverageTemperature\"),\n",
    "    col(\"City\"),\n",
    "    col(\"Country\")\n",
    ").filter(col(\"Country\") == \"United States\")\n",
    "\n",
    "temperature_dim = temperature_dim.dropDuplicates([\"dt\"])\n",
    "\n",
    "# Load the demographic data\n",
    "demographic_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .load('./Cleaned Data/df_demographics.csv')\n",
    "\n",
    "# Select relevant columns and rename them form demographic_df:\n",
    "demographic_dim = demographic_df.select(\n",
    "    col(\"City\"),\n",
    "    col(\"State\"),\n",
    "    col(\"Median Age\").alias(\"median_age\"),\n",
    "    col(\"Male Population\").alias(\"male_population\"),\n",
    "    col(\"Female Population\").alias(\"female_population\"),\n",
    "    col(\"Total Population\").alias(\"total_population\"),\n",
    "    col(\"Number of Veterans\").alias(\"num_veterans\"),\n",
    "    col(\"Foreign-born\").alias(\"num_foreign_born\"),\n",
    "    col(\"Average Household Size\").alias(\"avg_household_size\"),\n",
    "    col(\"State Code\").alias(\"state_code\"),\n",
    "    col(\"Race\"),\n",
    "    col(\"Count\")\n",
    ")\n",
    "\n",
    "demographic_dim = demographic_dim.dropDuplicates([\"City\", \"State\"])\n",
    "demographic_dim = demographic_dim.withColumnRenamed(\"City\", \"arrival_city\")\n",
    "# Load the airport data\n",
    "airport_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .load('./Cleaned Data/df_airport_codes.csv')\n",
    "\n",
    "# Select relevant columns and rename them from airport_df:\n",
    "airport_schema = StructType([\n",
    "    StructField(\"ident\", StringType(), True),\n",
    "    StructField(\"type\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"elevation_ft\", DoubleType(), True),\n",
    "    StructField(\"iso_country\", StringType(), True),\n",
    "    StructField(\"iso_region\", StringType(), True),\n",
    "    StructField(\"municipality\", StringType(), True),\n",
    "    StructField(\"gps_code\", StringType(), True),\n",
    "    StructField(\"iata_code\", StringType(), True),\n",
    "    StructField(\"local_code\", StringType(), True),\n",
    "    StructField(\"longitude\", DoubleType(), True),\n",
    "    StructField(\"latitude\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "airport_dim = airport_df.select(\n",
    "    col(\"ident\"),\n",
    "    col(\"type\"),\n",
    "    col(\"name\"),\n",
    "    col(\"iso_country\"),\n",
    "    col(\"iso_region\"),\n",
    "    col(\"municipality\"),\n",
    "    col(\"gps_code\"),\n",
    "    col(\"iata_code\"),\n",
    "    col(\"local_code\"),\n",
    "    col(\"longitude\"),\n",
    "    col(\"latitude\"),\n",
    "    col(\"elevation_ft\").cast(DoubleType()).alias(\"elevation_ft\")\n",
    ").filter(col(\"elevation_ft\").isNotNull() & col(\"elevation_ft\").cast(\"string\").rlike(\"^\\\\d+\\\\.?\\\\d*$\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+-----------------------+---------------------------+--------+------------+--------------+------------+-------------+----+---------+-----+----------+------+-------+--------------+----------+--------+\n",
      "|cicid|  year|month|immigrant_birth_country|immigrant_residence_country|adm_port|arrival_date|departure_date|arrival_mode|arrival_state| age|visa_type|count|birth_year|gender|airline| admission_num|flight_num|visatype|\n",
      "+-----+------+-----+-----------------------+---------------------------+--------+------------+--------------+------------+-------------+----+---------+-----+----------+------+-------+--------------+----------+--------+\n",
      "|  6.0|2016.0|  4.0|                  692.0|                      692.0|     XXX|     20573.0|          null|        null|         null|37.0|      2.0|  1.0|    1979.0|  null|   null| 1.897628485E9|      null|      B2|\n",
      "|  7.0|2016.0|  4.0|                  254.0|                      276.0|     ATL|     20551.0|          null|         1.0|           AL|25.0|      3.0|  1.0|    1991.0|     M|   null|  3.73679633E9|     00296|      F1|\n",
      "| 15.0|2016.0|  4.0|                  101.0|                      101.0|     WAS|     20545.0|       20691.0|         1.0|           MI|55.0|      2.0|  1.0|    1961.0|     M|     OS|  6.66643185E8|        93|      B2|\n",
      "| 16.0|2016.0|  4.0|                  101.0|                      101.0|     NYC|     20545.0|       20567.0|         1.0|           MA|28.0|      2.0|  1.0|    1988.0|  null|     AA|9.246846133E10|     00199|      B2|\n",
      "| 17.0|2016.0|  4.0|                  101.0|                      101.0|     NYC|     20545.0|       20567.0|         1.0|           MA| 4.0|      2.0|  1.0|    2012.0|  null|     AA|9.246846313E10|     00199|      B2|\n",
      "| 18.0|2016.0|  4.0|                  101.0|                      101.0|     NYC|     20545.0|       20555.0|         1.0|           MI|57.0|      1.0|  1.0|    1959.0|  null|     AZ|9.247103803E10|     00602|      B1|\n",
      "| 19.0|2016.0|  4.0|                  101.0|                      101.0|     NYC|     20545.0|       20558.0|         1.0|           NJ|63.0|      2.0|  1.0|    1953.0|  null|     AZ|9.247139923E10|     00602|      B2|\n",
      "| 20.0|2016.0|  4.0|                  101.0|                      101.0|     NYC|     20545.0|       20558.0|         1.0|           NJ|57.0|      2.0|  1.0|    1959.0|  null|     AZ|9.247161383E10|     00602|      B2|\n",
      "| 21.0|2016.0|  4.0|                  101.0|                      101.0|     NYC|     20545.0|       20553.0|         1.0|           NY|46.0|      2.0|  1.0|    1970.0|  null|     AZ|9.247079603E10|     00602|      B2|\n",
      "| 22.0|2016.0|  4.0|                  101.0|                      101.0|     NYC|     20545.0|       20562.0|         1.0|           NY|48.0|      1.0|  1.0|    1968.0|  null|     AZ|9.247848973E10|     00608|      B1|\n",
      "+-----+------+-----+-----------------------+---------------------------+--------+------------+--------------+------------+-------------+----+---------+-----+----------+------+-------+--------------+----------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_fact.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+-------+-------------+\n",
      "|                 dt|AverageTemperature|   City|      Country|\n",
      "+-------------------+------------------+-------+-------------+\n",
      "|1750-03-01 00:00:00|              3.01|  Akron|United States|\n",
      "|1753-03-01 00:00:00|4.2189999999999985|  Akron|United States|\n",
      "|1798-04-01 00:00:00|             9.274|  Akron|United States|\n",
      "|1828-12-01 00:00:00|             7.648|Abilene|United States|\n",
      "|1854-05-01 00:00:00|            20.789|Abilene|United States|\n",
      "|1870-01-01 00:00:00| 5.976000000000001|Abilene|United States|\n",
      "|1879-10-01 00:00:00|            18.047|Abilene|United States|\n",
      "|1893-11-01 00:00:00|              9.03|Abilene|United States|\n",
      "|1896-04-01 00:00:00|            18.524|Abilene|United States|\n",
      "|1902-09-01 00:00:00|21.930999999999997|Abilene|United States|\n",
      "+-------------------+------------------+-------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperature_dim.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+----------+---------------+-----------------+----------------+------------+----------------+------------------+----------+--------------------+------+\n",
      "|        arrival_city|         State|median_age|male_population|female_population|total_population|num_veterans|num_foreign_born|avg_household_size|state_code|                Race| Count|\n",
      "+--------------------+--------------+----------+---------------+-----------------+----------------+------------+----------------+------------------+----------+--------------------+------+\n",
      "|          Cincinnati|          Ohio|      32.7|       143654.0|         154883.0|          298537|     13699.0|         16896.0|              2.08|        OH|               White|162245|\n",
      "|         Kansas City|        Kansas|      33.4|        74606.0|          76655.0|          151261|      8139.0|         25507.0|              2.71|        KS|Black or African-...| 40177|\n",
      "|           Lynchburg|      Virginia|      28.7|        38614.0|          41198.0|           79812|      4322.0|          4364.0|              2.48|        VA|Black or African-...| 23271|\n",
      "|              Auburn|    Washington|      37.1|        36837.0|          39743.0|           76580|      5401.0|         14842.0|              2.73|        WA|               Asian| 12341|\n",
      "|              Dayton|          Ohio|      32.8|        66631.0|          73966.0|          140597|      8465.0|          7381.0|              2.26|        OH|               Asian|  1885|\n",
      "|Louisville/Jeffer...|      Kentucky|      37.5|       298451.0|         316938.0|          615389|     39364.0|         37875.0|              2.45|        KY|               White|456451|\n",
      "|              Austin|         Texas|      32.7|       475718.0|         456122.0|          931840|     37414.0|        181686.0|               2.5|        TX|  Hispanic or Latino|327680|\n",
      "|           Camarillo|    California|      40.8|        31941.0|          35682.0|           67623|      4384.0|          9735.0|              2.77|        CA|American Indian a...|   742|\n",
      "|          Pittsburgh|  Pennsylvania|      32.9|       149690.0|         154695.0|          304385|     17728.0|         28187.0|              2.13|        PA|               White|208863|\n",
      "|              Upland|    California|      39.7|        36226.0|          40221.0|           76447|      2898.0|         16552.0|              2.77|        CA|Black or African-...|  5717|\n",
      "|            Columbus|          Ohio|      32.5|       413981.0|         435086.0|          849067|     40238.0|        101129.0|               2.4|        OH|               Asian| 48974|\n",
      "|          High Point|North Carolina|      35.5|        51751.0|          58077.0|          109828|      5204.0|         16315.0|              2.65|        NC|               Asian| 11060|\n",
      "|         New Bedford| Massachusetts|      38.6|        43793.0|          51166.0|           94959|      4185.0|         19024.0|              2.39|        MA|               White| 63938|\n",
      "|       Newport Beach|    California|      46.8|        43161.0|          43970.0|           87131|      4847.0|         15318.0|               2.4|        CA|  Hispanic or Latino|  8127|\n",
      "|             Shawnee|        Kansas|      40.1|        32313.0|          32745.0|           65058|      3575.0|          4136.0|              2.64|        KS|  Hispanic or Latino|  4864|\n",
      "|          Sugar Land|         Texas|      42.1|        43889.0|          44240.0|           88129|      4377.0|         31169.0|              2.95|        TX|               Asian| 33469|\n",
      "|            Appleton|     Wisconsin|      35.6|        37217.0|          38038.0|           75255|      4219.0|          4454.0|              2.49|        WI|Black or African-...|  3407|\n",
      "|        Lehigh Acres|       Florida|      34.3|        57856.0|          61624.0|          119480|      5551.0|         31880.0|              3.55|        FL|Black or African-...| 29998|\n",
      "|             Livonia|      Michigan|      47.4|        45369.0|          49264.0|           94633|      5397.0|          7175.0|              2.52|        MI|               White| 87383|\n",
      "|              Newton| Massachusetts|      42.3|        41985.0|          46824.0|           88809|      1814.0|         21692.0|              2.71|        MA|Black or African-...|  2925|\n",
      "+--------------------+--------------+----------+---------------+-----------------+----------------+------------+----------------+------------------+----------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demographic_dim.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+-----------+----------+---------------+--------+---------+----------+-------------------+------------------+------------+\n",
      "|ident|         type|                name|iso_country|iso_region|   municipality|gps_code|iata_code|local_code|          longitude|          latitude|elevation_ft|\n",
      "+-----+-------------+--------------------+-----------+----------+---------------+--------+---------+----------+-------------------+------------------+------------+\n",
      "| 07FA|small_airport|Ocean Reef Club A...|         US|     US-FL|      Key Largo|    07FA|      OCA|      07FA|   -80.274803161621|25.325399398804002|         8.0|\n",
      "| 0CO2|small_airport|Crested Butte Air...|         US|     US-CO|  Crested Butte|    0CO2|      CSE|      0CO2|-106.92834099999999|         38.851918|      8980.0|\n",
      "| 0TE7|small_airport|   LBJ Ranch Airport|         US|     US-TX|   Johnson City|    0TE7|      JCY|      0TE7|     -98.6224975586|30.251800537100006|      1515.0|\n",
      "| 13MA|small_airport|Metropolitan Airport|         US|     US-MA|         Palmer|    13MA|      PMX|      13MA| -72.31140136719998|42.223300933800004|       418.0|\n",
      "|  13Z|seaplane_base|Loring Seaplane Base|         US|     US-AK|         Loring|     13Z|      WLR|       13Z|     -131.636993408|55.601299285900005|         0.0|\n",
      "|  16A|small_airport| Nunapitchuk Airport|         US|     US-AK|    Nunapitchuk|    PPIT|      NUP|       16A|-162.44045400000002|         60.905591|        12.0|\n",
      "|  16K|seaplane_base|Port Alice Seapla...|         US|     US-AK|     Port Alice|     16K|      PTC|       16K|           -133.597|55.803000000000004|         0.0|\n",
      "| 19AK|small_airport|     Icy Bay Airport|         US|     US-AK|        Icy Bay|    19AK|      ICY|      19AK|     -141.662002563|       59.96900177|        50.0|\n",
      "|  19P|seaplane_base|Port Protection S...|         US|     US-AK|Port Protection|     19P|      PPV|       19P|   -133.61000061035|56.328800201415994|         0.0|\n",
      "|  1KC|small_airport|Kalakaket Creek A...|         US|     US-AK|Kalakaket Creek|     1KC|      KKK|       1KC|     -156.820392609|     64.4166256967|      1598.0|\n",
      "+-----+-------------+--------------------+-----------+----------+---------------+--------+---------+----------+-------------------+------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airport_dim.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+----------------+\n",
      "|  arrival_city|num_immigrants|num_foreign_born|\n",
      "+--------------+--------------+----------------+\n",
      "|  Jacksonville|      645076.0|  5.333592615E10|\n",
      "| Pompano Beach|      621701.0| 2.0350138833E10|\n",
      "|   Tallahassee|      621701.0|  1.039484072E10|\n",
      "|   Spring Hill|      621701.0|   4.907085993E9|\n",
      "|Pembroke Pines|      621701.0|  3.867601921E10|\n",
      "|         Largo|      621701.0|   6.521021789E9|\n",
      "|         Davie|      621701.0| 1.6494970932E10|\n",
      "|     Poinciana|      621701.0|   8.920787649E9|\n",
      "|     Hollywood|      621701.0| 3.4291783758E10|\n",
      "| Coral Springs|      621701.0| 2.3967816952E10|\n",
      "+--------------+--------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "creating a query to group count immigrants by their cities and include the \"num_foreign_born\" field in this city. \n",
    "The results could be ordered by the immigrant counts to see if cities with the most immigrants are indeed cities \n",
    "with the largest foreign-born counts.\n",
    "\"\"\"\n",
    "# Join immigration_fact and demographic_dim on arrival_city\n",
    "joined_df = immigration_fact.join(demographic_dim, immigration_fact.arrival_state == demographic_dim.state_code, \"inner\")\n",
    "\n",
    "# Group by arrival_city and sum the immigration_fact.count and demographic_dim.num_foreign_born columns\n",
    "result_df = joined_df.groupBy(\"arrival_city\") \\\n",
    "    .agg(sum(immigration_fact[\"count\"]).alias(\"num_immigrants\"), sum(\"num_foreign_born\").alias(\"num_foreign_born\")) \\\n",
    "    .orderBy(\"num_immigrants\", ascending=False)\n",
    "\n",
    "# Show the top 10 cities by immigrant count and their corresponding num_foreign_born count\n",
    "result_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+----------------+\n",
      "|    arrival_city|num_immigrants|num_foreign_born|\n",
      "+----------------+--------------+----------------+\n",
      "|    Jacksonville|      645076.0|  5.333592615E10|\n",
      "|      Clearwater|      621701.0| 1.0995403886E10|\n",
      "|         Deltona|      621701.0|   4.412833698E9|\n",
      "|        Lakeland|      621701.0|   7.206757992E9|\n",
      "|         Hialeah|      621701.0|1.05781181748E11|\n",
      "|      Boca Raton|      621701.0| 1.3128460017E10|\n",
      "|      Plantation|      621701.0| 1.7346701302E10|\n",
      "|      Palm Coast|      621701.0|   5.647531884E9|\n",
      "|Saint Petersburg|      621701.0| 1.7760132467E10|\n",
      "| West Palm Beach|      621701.0| 1.9070678175E10|\n",
      "|      Lauderhill|      621701.0| 1.5835346171E10|\n",
      "|           Davie|      621701.0| 1.6494970932E10|\n",
      "|           Largo|      621701.0|   6.521021789E9|\n",
      "|   Coral Springs|      621701.0| 2.3967816952E10|\n",
      "|         Kendall|      621701.0|  1.938463718E10|\n",
      "|     Tallahassee|      621701.0|  1.039484072E10|\n",
      "|           Tampa|      621701.0| 3.6552910295E10|\n",
      "|       Melbourne|      621701.0|   6.021174185E9|\n",
      "|   Boynton Beach|      621701.0|   9.593468131E9|\n",
      "|Port Saint Lucie|      621701.0| 2.1139699103E10|\n",
      "|     Gainesville|      621701.0|   9.494617672E9|\n",
      "|    Delray Beach|      621701.0| 1.0344482939E10|\n",
      "|        Palm Bay|      621701.0|    7.50393107E9|\n",
      "|   Miami Gardens|      621701.0| 2.0761083194E10|\n",
      "|    Lehigh Acres|      621701.0|  1.981982788E10|\n",
      "|         Alafaya|      621701.0|   9.848987242E9|\n",
      "|  Pembroke Pines|      621701.0|  3.867601921E10|\n",
      "|          Weston|      621701.0| 1.9195640076E10|\n",
      "|Town 'n' Country|      621701.0| 1.3761351635E10|\n",
      "|      Cape Coral|      621701.0| 1.5035838685E10|\n",
      "|       Poinciana|      621701.0|   8.920787649E9|\n",
      "|     Miami Beach|      621701.0| 3.1027853508E10|\n",
      "|       Riverview|      621701.0|    7.60962024E9|\n",
      "|           Miami|      621701.0|1.62132782089E11|\n",
      "|         Miramar|      621701.0| 3.5548241479E10|\n",
      "|       Kissimmee|      621701.0| 1.0493691179E10|\n",
      "|         Brandon|      621701.0|  1.018967939E10|\n",
      "|         Sunrise|      621701.0| 2.3754573509E10|\n",
      "|         Orlando|      621701.0| 3.1431959158E10|\n",
      "|      Fort Myers|      621701.0|   9.552435865E9|\n",
      "|      Pine Hills|      621701.0| 1.2890970235E10|\n",
      "| Deerfield Beach|      621701.0| 1.4698255042E10|\n",
      "|       Hollywood|      621701.0| 3.4291783758E10|\n",
      "| Fort Lauderdale|      621701.0| 2.9581776982E10|\n",
      "|   Pompano Beach|      621701.0| 2.0350138833E10|\n",
      "|     Spring Hill|      621701.0|   4.907085993E9|\n",
      "|       Homestead|      621701.0| 1.5174478008E10|\n",
      "|        Pasadena|      604707.0| 2.4295739806E10|\n",
      "|          Albany|      598340.0|   6.653787639E9|\n",
      "|       Rochester|      564871.0| 1.0018300617E10|\n",
      "|     Cheektowaga|      553677.0|   1.955587164E9|\n",
      "|         Yonkers|      553677.0| 3.3911055219E10|\n",
      "|       Brentwood|      553677.0| 1.4981392266E10|\n",
      "|        Syracuse|      553677.0|   9.818354241E9|\n",
      "|        New York|      553677.0| 1.7786873625E12|\n",
      "|    Mount Vernon|      553677.0| 1.3164778029E10|\n",
      "|         Buffalo|      553677.0|  1.363706451E10|\n",
      "|    New Rochelle|      553677.0|  1.492713192E10|\n",
      "|     Schenectady|      553677.0|   6.068853597E9|\n",
      "|      Union City|      546917.0| 1.8509643915E10|\n",
      "|        Richmond|      501785.0| 2.0351596649E10|\n",
      "|         Concord|      493761.0| 1.7812405833E10|\n",
      "|        Glendale|      490604.0| 5.3345023854E10|\n",
      "|        Lakewood|      486260.0|    8.82075247E9|\n",
      "|     Westminster|      486260.0| 2.0043334136E10|\n",
      "|         Norwalk|      484377.0| 1.8843717904E10|\n",
      "|      Santa Rosa|      470386.0|  1.552979379E10|\n",
      "|     Los Angeles|      470386.0| 6.9872312405E11|\n",
      "|       Lancaster|      470386.0|   8.112747342E9|\n",
      "|       Inglewood|      470386.0| 1.6073560006E10|\n",
      "|       Santa Ana|      470386.0| 7.1968587614E10|\n",
      "|          Fresno|      470386.0| 4.8662842858E10|\n",
      "|   Jurupa Valley|      470386.0| 1.1918640468E10|\n",
      "|         Lynwood|      470386.0| 1.3199501546E10|\n",
      "|    San Clemente|      470386.0|   3.814360074E9|\n",
      "|     Victorville|      470386.0| 1.0329206174E10|\n",
      "|         Fontana|      470386.0| 2.8904278928E10|\n",
      "|        Temecula|      470386.0|   8.882769224E9|\n",
      "|            Napa|      470386.0|   8.678151314E9|\n",
      "|          Tustin|      470386.0| 1.1775643124E10|\n",
      "|       Pittsburg|      470386.0|   9.898332598E9|\n",
      "|          Irvine|      470386.0| 5.4736937276E10|\n",
      "|        Whittier|      470386.0|    8.06476797E9|\n",
      "|   Moreno Valley|      470386.0| 2.5608754612E10|\n",
      "|     Bakersfield|      470386.0|  3.366787795E10|\n",
      "|          Upland|      470386.0|   7.785829072E9|\n",
      "|   San Francisco|      470386.0|1.39798248814E11|\n",
      "|       Livermore|      470386.0|   6.566118174E9|\n",
      "|      Bellflower|      470386.0| 1.1574788302E10|\n",
      "|           Indio|      470386.0| 1.0601559668E10|\n",
      "|   Mission Viejo|      470386.0|   8.141440888E9|\n",
      "|         Manteca|      470386.0|   6.558121612E9|\n",
      "|         Compton|      470386.0|  1.442203476E10|\n",
      "|       Palo Alto|      470386.0| 1.0982572328E10|\n",
      "|Rancho Cucamonga|      470386.0| 1.5935736908E10|\n",
      "|     Santa Clara|      470386.0| 2.4592250466E10|\n",
      "|           Chico|      470386.0|    3.96300205E9|\n",
      "|       Elk Grove|      470386.0| 1.8200645498E10|\n",
      "|           Hemet|      470386.0|    6.27024538E9|\n",
      "|       Fullerton|      470386.0| 2.0416633944E10|\n",
      "+----------------+--------------+----------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_parquet(df, partition_cols, path):\n",
    "    df.write.mode('overwrite').partitionBy(*partition_cols).parquet(path)\n",
    "    \n",
    "# Define the path where the Parquet files will be saved\n",
    "output_path = \"./Transformed Data/\"\n",
    "\n",
    "# Write the immigration_fact data frame to Parquet\n",
    "write_to_parquet(immigration_fact, [\"year\", \"month\"], output_path + \"immigration_fact\")\n",
    "\n",
    "# Write the temperature_dim data frame to Parquet\n",
    "write_to_parquet(temperature_dim, [\"City\"], output_path + \"temperature_dim\")\n",
    "\n",
    "# Write the demographic_dim data frame to Parquet\n",
    "write_to_parquet(demographic_dim, [\"arrival_city\", \"State\"], output_path + \"demographic_dim\")\n",
    "\n",
    "# Write the airport_dim data frame to Parquet\n",
    "write_to_parquet(airport_dim, [\"iso_country\"], output_path + \"airport_dim\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### immigration_fact Data Quality Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def immigration_fact_data_quality_check(immigration_fact):   \n",
    "    # Check for missing values in the cicid column\n",
    "    if immigration_fact.filter(col(\"cicid\").isNull()).count() > 0:\n",
    "        raise ValueError(\"immigration_fact data frame has missing values in the cicid column\")\n",
    "\n",
    "    # Check for duplicates in the cicid column\n",
    "    if immigration_fact.count() != immigration_fact.select(\"cicid\").distinct().count():\n",
    "        raise ValueError(\"immigration_fact data frame has duplicates in the cicid column\")\n",
    "\n",
    "    # Check that the year and month columns contain valid values\n",
    "    if immigration_fact.filter(col(\"year\") < 2016).count() > 0:\n",
    "        raise ValueError(\"immigration_fact data frame has invalid values in the year column\")\n",
    "    if immigration_fact.filter(col(\"year\") > 2020).count() > 0:\n",
    "        raise ValueError(\"immigration_fact data frame has invalid values in the year column\")\n",
    "    if immigration_fact.filter(col(\"month\") < 1).count() > 0:\n",
    "        raise ValueError(\"immigration_fact data frame has invalid values in the month column\")\n",
    "    if immigration_fact.filter(col(\"month\") > 12).count() > 0:\n",
    "        raise ValueError(\"immigration_fact data frame has invalid values in the month column\")\n",
    "    \n",
    "immigration_fact_quality_check = immigration_fact_data_quality_check(immigration_fact) \n",
    "immigration_fact_quality_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### temperature_dim Data Quality Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temperature_dim_data_quality_check(temperature_dim):    \n",
    "    # Check for missing values in the dt column\n",
    "    if temperature_dim.filter(col(\"dt\").isNull()).count() > 0:\n",
    "        raise ValueError(\"temperature_dim data frame has missing values in the dt column\")\n",
    "\n",
    "    # Check for duplicates in the dt column\n",
    "    if temperature_dim.count() != temperature_dim.select(\"dt\").distinct().count():\n",
    "        raise ValueError(\"temperature_dim data frame has duplicates in the dt column\")\n",
    "\n",
    "    # Check that the AverageTemperature column contains valid values\n",
    "    if temperature_dim.filter(col(\"AverageTemperature\") < -100).count() > 0:\n",
    "        raise ValueError(\"temperature_dim data frame has invalid values in the AverageTemperature column\")\n",
    "    if temperature_dim.filter(col(\"AverageTemperature\") > 100).count() > 0:\n",
    "        raise ValueError(\"temperature_dim data frame has invalid values in the AverageTemperature column\")\n",
    "           \n",
    "temperature_dim_quality_check = temperature_dim_data_quality_check(temperature_dim) \n",
    "temperature_dim_quality_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### demographic_dim Data Quality Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demographic_dim_data_quality_check(demographic_dim):\n",
    "    # Check for missing values in the City and State columns\n",
    "    if demographic_dim.filter(col(\"arrival_city\").isNull() | col(\"State\").isNull()).count() > 0:\n",
    "        raise ValueError(\"demographic_dim data frame has missing values in the City or State column\")\n",
    "\n",
    "    # Check for duplicates in the combination of City and State columns\n",
    "    if demographic_dim.count() != demographic_dim.select(\"arrival_city\", \"State\").distinct().count():\n",
    "        raise ValueError(\"demographic_dim data frame has duplicates in the combination of City and State columns\")\n",
    "\n",
    "    # Check that the median_age, male_population, female_population, total_population,\n",
    "    # num_veterans, num_foreign_born, and avg_household_size columns contain valid values\n",
    "    if demographic_dim.filter(col(\"median_age\") < 0).count() > 0:\n",
    "        raise ValueError(\"demographic_dim data frame has invalid values in the median_age column\")\n",
    "    if demographic_dim.filter(col(\"male_population\") < 0).count() > 0:\n",
    "        raise ValueError(\"demographic_dim data frame has invalid values in the male_population column\")\n",
    "    if demographic_dim.filter(col(\"female_population\") < 0).count() > 0:\n",
    "        raise ValueError(\"demographic_dim data frame has invalid values in the female_population column\")\n",
    "    if demographic_dim.filter(col(\"total_population\") < 0).count() > 0:\n",
    "        raise ValueError(\"demographic_dim data frame has invalid values in the total_population column\")\n",
    "    if demographic_dim.filter(col(\"num_veterans\") < 0).count() > 0:\n",
    "        raise ValueError(\"demographic_dim data frame has invalid values in the num_veterans column\")\n",
    "    if demographic_dim.filter(col(\"num_foreign_born\") < 0).count() > 0:\n",
    "        raise ValueError(\"demographic_dim data frame has invalid values in the num_foreign_born column\")\n",
    "    if demographic_dim.filter(col(\"avg_household_size\") < 0).count() > 0:\n",
    "        raise ValueError(\"demographic_dim data frame has invalid values in the avg_household_size column\")       \n",
    "        \n",
    "demographic_dim_quality_check = demographic_dim_data_quality_check(demographic_dim) \n",
    "demographic_dim_quality_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### airport_dim  Data Quality Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def airport_dim_data_quality_check(airport_dim):\n",
    "    # Check for missing values in the ident column\n",
    "    if airport_dim.filter(col(\"ident\").isNull()).count() > 0:\n",
    "        raise ValueError(\"airport_dim data frame has missing values in the ident column\")\n",
    "\n",
    "    # Check for duplicates in the ident column\n",
    "    if airport_dim.count() != airport_dim.select(\"ident\").distinct().count():\n",
    "        raise ValueError(\"airport_dim data frame has duplicates in the ident column\")\n",
    "\n",
    "    # Check that the elevation_ft, longitude, and latitude columns contain valid values\n",
    "    if airport_dim.filter(col(\"elevation_ft\").isNull()).count() > 0:\n",
    "        raise ValueError(\"airport_dim data frame has missing values in the elevation_ft column\")\n",
    "    if airport_dim.filter(col(\"longitude\").isNull()).count() > 0:\n",
    "        raise ValueError(\"airport_dim data frame has missing values in the longitude column\")\n",
    "    if airport_dim.filter(col(\"latitude\").isNull()).count() > 0:\n",
    "        raise ValueError(\"airport_dim data frame has missing values in the latitude column\")\n",
    "    if airport_dim.filter(col(\"elevation_ft\") < 0).count() > 0:\n",
    "        raise ValueError(\"airport_dim data frame has invalid values in the elevation_ft column\")\n",
    "\n",
    "airport_dim_quality_check = airport_dim_data_quality_check(airport_dim) \n",
    "airport_dim_quality_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_dict = {\n",
    "    \"immigration\": {\n",
    "        \"immigration_fact\": {\n",
    "            \"cicid\": \"ID number for each record\",\n",
    "            \"year\": \"4 digit year of arrival\",\n",
    "            \"month\": \"Numeric month of arrival\",\n",
    "            \"immigrant_birth_country\": \"3 digit code for immigrant's country of birth\",\n",
    "            \"immigrant_residence_country\": \"3 digit code for immigrant's country of residence\",\n",
    "            \"adm_port\": \"Port of admission into the US\",\n",
    "            \"arrival_date\": \"Arrival date in the US in SAS format\",\n",
    "            \"departure_date\": \"Departure date from the US in SAS format\",\n",
    "            \"arrival_mode\": \"Mode of arrival into the US\",\n",
    "            \"arrival_state\": \"US state of arrival\",\n",
    "            \"age\": \"Age of immigrant\",\n",
    "            \"visa_type\": \"Visa category for immigrant as double type\",\n",
    "            \"count\": \"Number of immigrants with same characteristics\",\n",
    "            \"birth_year\": \"Year of birth for immigrant\",\n",
    "            \"gender\": \"Gender of immigrant\",\n",
    "            \"airline\": \"Airline used to arrive in the US\",\n",
    "            \"admission_num\": \"Admission number for immigrant\",\n",
    "            \"flight_num\": \"Flight number of airline used to arrive in the US\",\n",
    "            \"visatype\": \"Visa category for immigrant as string type\"\n",
    "        }\n",
    "    },\n",
    "    \"temperature\": {\n",
    "        \"temperature_dim\": {\n",
    "            \"dt\": \"Date in format (YYYY-MM-DD) of temperature observation\",\n",
    "            \"AverageTemperature\": \"Average temperature for the city on the given date\",\n",
    "            \"City\": \"Name of the city where the observation was taken\",\n",
    "            \"Country\": \"Country where the city is located\"\n",
    "        }\n",
    "    },\n",
    "    \"demographics\": {\n",
    "        \"demographic_dim\": {\n",
    "            \"arrival_city\": \"Name of the city\",\n",
    "            \"State\": \"US state where the city is located\",\n",
    "            \"median_age\": \"Median age of the population in the city\",\n",
    "            \"male_population\": \"Number of males in the population of the city\",\n",
    "            \"female_population\": \"Number of females in the population of the city\",\n",
    "            \"total_population\": \"Total number of people in the city\",\n",
    "            \"num_veterans\": \"Number of veterans in the population of the city\",\n",
    "            \"num_foreign_born\": \"Number of foreign-born individuals in the population of the city\",\n",
    "            \"avg_household_size\": \"Average household size in the city\",\n",
    "            \"state_code\": \"2 letter code for the US state where the city is located\",\n",
    "            \"Race\": \"Ethnicity of the population\",\n",
    "            \"Count\": \"Number of individuals in the population with the specified ethnicity\"\n",
    "        }\n",
    "    },\n",
    "    \"airports\": {\n",
    "        \"airport_dim\": {\n",
    "            \"ident\": \"Unique identifier for the airport\",\n",
    "            \"type\": \"Type of airport (small, medium, large)\",\n",
    "            \"name\": \"Name of airport\",\n",
    "            \"continent\": \"Continent where airport is located\",\n",
    "            \"iso_country\": \"ISO code for the country where the airport is located\",\n",
    "            \"iso_region\": \"ISO code for the region where the airport is located\",\n",
    "            \"municipality\": \"Municipality where the airport is located\",\n",
    "            \"gps_code\": \"GPS code for the airport\",\n",
    "            \"iata_code\": \"IATA code for the airport\",\n",
    "            \"local_code\": \"Local code for the airport\",\n",
    "             \"Latitude and longitude of the airport\"\n",
    "            \"longitude\":\"longitude of the airport\",\n",
    "            \"latitude\": \"Latitude of the airport\",\n",
    "            \"elevation_ft\": \"Airport altitude \"\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Table</th>\n",
       "      <th>Column</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>immigration</td>\n",
       "      <td>immigration_fact.cicid</td>\n",
       "      <td>ID number for each record</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>immigration</td>\n",
       "      <td>immigration_fact.year</td>\n",
       "      <td>4 digit year of arrival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>immigration</td>\n",
       "      <td>immigration_fact.month</td>\n",
       "      <td>Numeric month of arrival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>immigration</td>\n",
       "      <td>immigration_fact.immigrant_birth_country</td>\n",
       "      <td>3 digit code for immigrant's country of birth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>immigration</td>\n",
       "      <td>immigration_fact.immigrant_residence_country</td>\n",
       "      <td>3 digit code for immigrant's country of residence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>immigration</td>\n",
       "      <td>immigration_fact.adm_port</td>\n",
       "      <td>Port of admission into the US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>immigration</td>\n",
       "      <td>immigration_fact.arrival_date</td>\n",
       "      <td>Arrival date in the US in SAS format</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>immigration</td>\n",
       "      <td>immigration_fact.departure_date</td>\n",
       "      <td>Departure date from the US in SAS format</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>immigration</td>\n",
       "      <td>immigration_fact.arrival_mode</td>\n",
       "      <td>Mode of arrival into the US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>immigration</td>\n",
       "      <td>immigration_fact.arrival_state</td>\n",
       "      <td>US state of arrival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>immigration</td>\n",
       "      <td>immigration_fact.age</td>\n",
       "      <td>Age of immigrant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>immigration</td>\n",
       "      <td>immigration_fact.visa_type</td>\n",
       "      <td>Visa category for immigrant as double type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>immigration</td>\n",
       "      <td>immigration_fact.count</td>\n",
       "      <td>Number of immigrants with same characteristics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>immigration</td>\n",
       "      <td>immigration_fact.birth_year</td>\n",
       "      <td>Year of birth for immigrant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>immigration</td>\n",
       "      <td>immigration_fact.gender</td>\n",
       "      <td>Gender of immigrant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>immigration</td>\n",
       "      <td>immigration_fact.airline</td>\n",
       "      <td>Airline used to arrive in the US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>immigration</td>\n",
       "      <td>immigration_fact.admission_num</td>\n",
       "      <td>Admission number for immigrant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>immigration</td>\n",
       "      <td>immigration_fact.flight_num</td>\n",
       "      <td>Flight number of airline used to arrive in the US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>immigration</td>\n",
       "      <td>immigration_fact.visatype</td>\n",
       "      <td>Visa category for immigrant as string type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>temperature</td>\n",
       "      <td>temperature_dim.dt</td>\n",
       "      <td>Date in format (YYYY-MM-DD) of temperature obs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>temperature</td>\n",
       "      <td>temperature_dim.AverageTemperature</td>\n",
       "      <td>Average temperature for the city on the given ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>temperature</td>\n",
       "      <td>temperature_dim.City</td>\n",
       "      <td>Name of the city where the observation was taken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>temperature</td>\n",
       "      <td>temperature_dim.Country</td>\n",
       "      <td>Country where the city is located</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>demographics</td>\n",
       "      <td>demographic_dim.arrival_city</td>\n",
       "      <td>Name of the city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>demographics</td>\n",
       "      <td>demographic_dim.State</td>\n",
       "      <td>US state where the city is located</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>demographics</td>\n",
       "      <td>demographic_dim.median_age</td>\n",
       "      <td>Median age of the population in the city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>demographics</td>\n",
       "      <td>demographic_dim.male_population</td>\n",
       "      <td>Number of males in the population of the city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>demographics</td>\n",
       "      <td>demographic_dim.female_population</td>\n",
       "      <td>Number of females in the population of the city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>demographics</td>\n",
       "      <td>demographic_dim.total_population</td>\n",
       "      <td>Total number of people in the city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>demographics</td>\n",
       "      <td>demographic_dim.num_veterans</td>\n",
       "      <td>Number of veterans in the population of the city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>demographics</td>\n",
       "      <td>demographic_dim.num_foreign_born</td>\n",
       "      <td>Number of foreign-born individuals in the popu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>demographics</td>\n",
       "      <td>demographic_dim.avg_household_size</td>\n",
       "      <td>Average household size in the city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>demographics</td>\n",
       "      <td>demographic_dim.state_code</td>\n",
       "      <td>2 letter code for the US state where the city ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>demographics</td>\n",
       "      <td>demographic_dim.Race</td>\n",
       "      <td>Ethnicity of the population</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>demographics</td>\n",
       "      <td>demographic_dim.Count</td>\n",
       "      <td>Number of individuals in the population with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>airports</td>\n",
       "      <td>airport_dim.ident</td>\n",
       "      <td>Unique identifier for the airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>airports</td>\n",
       "      <td>airport_dim.type</td>\n",
       "      <td>Type of airport (small, medium, large)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>airports</td>\n",
       "      <td>airport_dim.name</td>\n",
       "      <td>Name of airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>airports</td>\n",
       "      <td>airport_dim.continent</td>\n",
       "      <td>Continent where airport is located</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>airports</td>\n",
       "      <td>airport_dim.iso_country</td>\n",
       "      <td>ISO code for the country where the airport is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>airports</td>\n",
       "      <td>airport_dim.iso_region</td>\n",
       "      <td>ISO code for the region where the airport is l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>airports</td>\n",
       "      <td>airport_dim.municipality</td>\n",
       "      <td>Municipality where the airport is located</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>airports</td>\n",
       "      <td>airport_dim.gps_code</td>\n",
       "      <td>GPS code for the airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>airports</td>\n",
       "      <td>airport_dim.iata_code</td>\n",
       "      <td>IATA code for the airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>airports</td>\n",
       "      <td>airport_dim.local_code</td>\n",
       "      <td>Local code for the airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>airports</td>\n",
       "      <td>airport_dim.Latitude and longitude of the airp...</td>\n",
       "      <td>longitude of the airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>airports</td>\n",
       "      <td>airport_dim.latitude</td>\n",
       "      <td>Latitude of the airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>airports</td>\n",
       "      <td>airport_dim.elevation_ft</td>\n",
       "      <td>Airport altitude</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Table                                             Column  \\\n",
       "0    immigration                             immigration_fact.cicid   \n",
       "1    immigration                              immigration_fact.year   \n",
       "2    immigration                             immigration_fact.month   \n",
       "3    immigration           immigration_fact.immigrant_birth_country   \n",
       "4    immigration       immigration_fact.immigrant_residence_country   \n",
       "5    immigration                          immigration_fact.adm_port   \n",
       "6    immigration                      immigration_fact.arrival_date   \n",
       "7    immigration                    immigration_fact.departure_date   \n",
       "8    immigration                      immigration_fact.arrival_mode   \n",
       "9    immigration                     immigration_fact.arrival_state   \n",
       "10   immigration                               immigration_fact.age   \n",
       "11   immigration                         immigration_fact.visa_type   \n",
       "12   immigration                             immigration_fact.count   \n",
       "13   immigration                        immigration_fact.birth_year   \n",
       "14   immigration                            immigration_fact.gender   \n",
       "15   immigration                           immigration_fact.airline   \n",
       "16   immigration                     immigration_fact.admission_num   \n",
       "17   immigration                        immigration_fact.flight_num   \n",
       "18   immigration                          immigration_fact.visatype   \n",
       "19   temperature                                 temperature_dim.dt   \n",
       "20   temperature                 temperature_dim.AverageTemperature   \n",
       "21   temperature                               temperature_dim.City   \n",
       "22   temperature                            temperature_dim.Country   \n",
       "23  demographics                       demographic_dim.arrival_city   \n",
       "24  demographics                              demographic_dim.State   \n",
       "25  demographics                         demographic_dim.median_age   \n",
       "26  demographics                    demographic_dim.male_population   \n",
       "27  demographics                  demographic_dim.female_population   \n",
       "28  demographics                   demographic_dim.total_population   \n",
       "29  demographics                       demographic_dim.num_veterans   \n",
       "30  demographics                   demographic_dim.num_foreign_born   \n",
       "31  demographics                 demographic_dim.avg_household_size   \n",
       "32  demographics                         demographic_dim.state_code   \n",
       "33  demographics                               demographic_dim.Race   \n",
       "34  demographics                              demographic_dim.Count   \n",
       "35      airports                                  airport_dim.ident   \n",
       "36      airports                                   airport_dim.type   \n",
       "37      airports                                   airport_dim.name   \n",
       "38      airports                              airport_dim.continent   \n",
       "39      airports                            airport_dim.iso_country   \n",
       "40      airports                             airport_dim.iso_region   \n",
       "41      airports                           airport_dim.municipality   \n",
       "42      airports                               airport_dim.gps_code   \n",
       "43      airports                              airport_dim.iata_code   \n",
       "44      airports                             airport_dim.local_code   \n",
       "45      airports  airport_dim.Latitude and longitude of the airp...   \n",
       "46      airports                               airport_dim.latitude   \n",
       "47      airports                           airport_dim.elevation_ft   \n",
       "\n",
       "                                          Description  \n",
       "0                           ID number for each record  \n",
       "1                             4 digit year of arrival  \n",
       "2                            Numeric month of arrival  \n",
       "3       3 digit code for immigrant's country of birth  \n",
       "4   3 digit code for immigrant's country of residence  \n",
       "5                       Port of admission into the US  \n",
       "6                Arrival date in the US in SAS format  \n",
       "7            Departure date from the US in SAS format  \n",
       "8                         Mode of arrival into the US  \n",
       "9                                 US state of arrival  \n",
       "10                                   Age of immigrant  \n",
       "11         Visa category for immigrant as double type  \n",
       "12     Number of immigrants with same characteristics  \n",
       "13                        Year of birth for immigrant  \n",
       "14                                Gender of immigrant  \n",
       "15                   Airline used to arrive in the US  \n",
       "16                     Admission number for immigrant  \n",
       "17  Flight number of airline used to arrive in the US  \n",
       "18         Visa category for immigrant as string type  \n",
       "19  Date in format (YYYY-MM-DD) of temperature obs...  \n",
       "20  Average temperature for the city on the given ...  \n",
       "21   Name of the city where the observation was taken  \n",
       "22                  Country where the city is located  \n",
       "23                                   Name of the city  \n",
       "24                 US state where the city is located  \n",
       "25           Median age of the population in the city  \n",
       "26      Number of males in the population of the city  \n",
       "27    Number of females in the population of the city  \n",
       "28                 Total number of people in the city  \n",
       "29   Number of veterans in the population of the city  \n",
       "30  Number of foreign-born individuals in the popu...  \n",
       "31                 Average household size in the city  \n",
       "32  2 letter code for the US state where the city ...  \n",
       "33                        Ethnicity of the population  \n",
       "34  Number of individuals in the population with t...  \n",
       "35                  Unique identifier for the airport  \n",
       "36             Type of airport (small, medium, large)  \n",
       "37                                    Name of airport  \n",
       "38                 Continent where airport is located  \n",
       "39  ISO code for the country where the airport is ...  \n",
       "40  ISO code for the region where the airport is l...  \n",
       "41          Municipality where the airport is located  \n",
       "42                           GPS code for the airport  \n",
       "43                          IATA code for the airport  \n",
       "44                         Local code for the airport  \n",
       "45                           longitude of the airport  \n",
       "46                            Latitude of the airport  \n",
       "47                                  Airport altitude   "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty list to store the rows of the table\n",
    "rows = []\n",
    "\n",
    "# Loop through each table and its nested dictionaries\n",
    "for table_name, table_dict in tables_dict.items():\n",
    "    for nested_table_name, nested_table_dict in table_dict.items():\n",
    "        # Loop through each column and its description in the nested dictionary\n",
    "        for column_name, column_description in nested_table_dict.items():\n",
    "            # Add a row to the list for each column and its description\n",
    "            rows.append([table_name, nested_table_name + '.' + column_name, column_description])\n",
    "\n",
    "# Create a DataFrame from the list of rows and add column names\n",
    "database_tables = pd.DataFrame(rows, columns=['Table', 'Column', 'Description'])\n",
    "\n",
    "# Display the DataFrame\n",
    "database_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the SparkSession\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    " * Clearly state the rationale for the choice of tools and technologies for the project: \n",
    "* To handle the massive amount of immigration data, which consists of around 3 million rows, we opted to leverage the power of Apache Spark. For other relatively smaller datasets, we utilized Pandas to manage them.\n",
    "\n",
    "\n",
    "\n",
    " * Propose how often the data should be updated and why: \n",
    "* Given that the primary dataset (I94 immigration dataset) is updated on a monthly basis, we need to ensure that our solution is updated monthly as well.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " * Write a description of how you would approach the problem differently under the following scenarios:\n",
    "* The data was increased by 100x: While we will continue to use Spark for handling the big data, we plan to scale up the number of nodes in our cluster. Additionally, we will leverage AWS to store our data in S3 and Redshift.\n",
    " \n",
    " \n",
    " \n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day: \n",
    "* Our ETL pipeline will be managed in a DAG using Apache Airflow, which will guarantee that the pipeline runs on time and performs data quality checks.\n",
    " \n",
    " \n",
    " \n",
    " * The database needed to be accessed by 100+ people: \n",
    "* To ensure that everyone can easily access our analytics database, we will migrate it to Amazon Redshift.\n",
    " \n",
    " \n",
    " \n",
    " * What schema are you using in this project? Does it have any advantage compared to other schemas?: \n",
    "* The schema used in this project is a star schema, which comprises of a central fact table (Immigration fact table) connected to several dimension tables (Temperature, Demographic, and Airport dimension tables) through foreign keys.\n",
    "* The advantage of using a star schema is that it simplifies queries and allows for faster performance, as data is denormalized and stored in a way that minimizes the number of joins required to retrieve data. This schema is also optimized for OLAP (Online Analytical Processing) queries, which involve complex queries that analyze large sets of data.\n",
    "\n",
    "\n",
    " * Why do you connect the entities the way you did in this project? Perhaps it is optimized for a particular query?:\n",
    "* The entities are connected in this way to enable efficient and effective querying of the data, as the foreign keys allow for easy join operations between the fact table and dimension tables. This schema is optimized for queries that involve aggregating data across multiple dimensions, such as analyzing immigration patterns by temperature, demographic, or airport information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
